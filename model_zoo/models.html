


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Built-In Zoo Models &mdash; FiftyOne 1.3.0 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/css/voxel51-website.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Remotely-Sourced Zoo Models" href="remote.html" />
    <link rel="prev" title="FiftyOne Model Zoo" href="index.html" />
<meta property="og:image" content="https://voxel51.com/wp-content/uploads/2024/03/3.24_webpages_Home_AV.png" />

<link
  href="https://fonts.googleapis.com/css?family=Palanquin:400,600,700,800"
  rel="stylesheet"
/>
<link
  href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css"
  rel="stylesheet"
/>
<script src="https://tag.clearbitscripts.com/v1/pk_b9ed71c8234edd4f77326bcbfab5a4ca/tags.js"></script>


  
  <script src="../_static/js/modernizr.min.js"></script>

  
</head>


<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <div class="ecosystem-dropdown">
              <a id="dropdownMenuButton" data-toggle="ecosystem-dropdown">
                Ecosystem
              </a>
              <div class="ecosystem-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/hub"">
                  <span class=dropdown-title>Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class=dropdown-title>Tools & Libraries</span>
                  <p>Explore the ecosystem of tools and libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <div class="resources-dropdown">
              <a id="resourcesDropdownButton" data-toggle="resources-dropdown">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/resources"">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class=dropdown-title>About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>



<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../teams/index.html">FiftyOne Teams ðŸš€</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../environments/index.html">Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/index.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/index.html">Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cheat_sheets/index.html">Cheat Sheets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../user_guide/index.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataset_zoo/index.html">Dataset Zoo</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../brain.html">FiftyOne Brain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../integrations/index.html">Integrations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../plugins/index.html">Plugins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cli/index.html">CLI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/fiftyone.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release-notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deprecation.html">Deprecation Notices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/index.html">FAQ</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="index.html">FiftyOne Model Zoo</a> &gt;</li>
        
      <li>Built-In Zoo Models</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Contents
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content style-external-links">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="built-in-zoo-models">
<span id="model-zoo-models"></span><h1>Built-In Zoo Models<a class="headerlink" href="#built-in-zoo-models" title="Permalink to this headline">Â¶</a></h1>
<p>This page lists all of the natively available models in the FiftyOne Model Zoo.</p>
<p>Check out the <a class="reference internal" href="api.html#model-zoo-api"><span class="std std-ref">API reference</span></a> for complete instructions
for using the Model Zoo.</p>
<div id="tutorial-cards-container">

<nav class="navbar navbar-expand-lg navbar-light tutorials-nav col-12">
    <div class="tutorial-tags-container">
        <div id="dropdown-filter-tags">
            <div class="tutorial-filter-menu">
                <div class="tutorial-filter filter-btn all-tag-selected" data-tag="all">All</div>
            </div>
        </div>
    </div>
</nav>

<hr class="tutorials-hr">

<div class="row">

<div id="tutorial-cards">
<div class="list"><p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Alexnet>

<div class="card tutorials-card" link=models.html#alexnet-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>alexnet-imagenet-torch</h4>
</div>

<p class="card-summary">AlexNet model architecture from "One weird trick for parallelizing convolutional neural networks" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Alexnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-2,Centernet>

<div class="card tutorials-card" link=models.html#centernet-hg104-1024-coco-tf2>

<div class="card-body">

<div class="card-title-container">
    <h4>centernet-hg104-1024-coco-tf2</h4>
</div>

<p class="card-summary">CenterNet model from "Objects as Points" with the Hourglass-104 backbone trained on COCO resized to 1024x1024</p>

<p class="tags">Detection,Coco,TensorFlow-2,Centernet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-2,Centernet>

<div class="card tutorials-card" link=models.html#centernet-hg104-512-coco-tf2>

<div class="card-body">

<div class="card-title-container">
    <h4>centernet-hg104-512-coco-tf2</h4>
</div>

<p class="card-summary">CenterNet model from "Objects as Points" with the Hourglass-104 backbone trained on COCO resized to 512x512</p>

<p class="tags">Detection,Coco,TensorFlow-2,Centernet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-2,Centernet,Mobilenet>

<div class="card tutorials-card" link=models.html#centernet-mobilenet-v2-fpn-512-coco-tf2>

<div class="card-body">

<div class="card-title-container">
    <h4>centernet-mobilenet-v2-fpn-512-coco-tf2</h4>
</div>

<p class="card-summary">CenterNet model from "Objects as Points" with the MobileNetV2 backbone trained on COCO resized to 512x512</p>

<p class="tags">Detection,Coco,TensorFlow-2,Centernet,Mobilenet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-2,Centernet,Resnet>

<div class="card tutorials-card" link=models.html#centernet-resnet101-v1-fpn-512-coco-tf2>

<div class="card-body">

<div class="card-title-container">
    <h4>centernet-resnet101-v1-fpn-512-coco-tf2</h4>
</div>

<p class="card-summary">CenterNet model from "Objects as Points" with the ResNet-101v1 backbone + FPN trained on COCO resized to 512x512</p>

<p class="tags">Detection,Coco,TensorFlow-2,Centernet,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-2,Centernet,Resnet>

<div class="card tutorials-card" link=models.html#centernet-resnet50-v1-fpn-512-coco-tf2>

<div class="card-body">

<div class="card-title-container">
    <h4>centernet-resnet50-v1-fpn-512-coco-tf2</h4>
</div>

<p class="card-summary">CenterNet model from "Objects as Points" with the ResNet-50-v1 backbone + FPN trained on COCO resized to 512x512</p>

<p class="tags">Detection,Coco,TensorFlow-2,Centernet,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-2,Centernet,Resnet>

<div class="card tutorials-card" link=models.html#centernet-resnet50-v2-512-coco-tf2>

<div class="card-body">

<div class="card-title-container">
    <h4>centernet-resnet50-v2-512-coco-tf2</h4>
</div>

<p class="card-summary">CenterNet model from "Objects as Points" with the ResNet-50v2 backbone trained on COCO resized to 512x512</p>

<p class="tags">Detection,Coco,TensorFlow-2,Centernet,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Logits,Embeddings,PyTorch,Transformers>

<div class="card tutorials-card" link=models.html#classification-transformer-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>classification-transformer-torch</h4>
</div>

<p class="card-summary">Hugging Face Transformers model for image classification</p>

<p class="tags">Classification,Logits,Embeddings,PyTorch,Transformers</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Logits,Embeddings,PyTorch,Clip,Zero-shot>

<div class="card tutorials-card" link=models.html#clip-vit-base32-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>clip-vit-base32-torch</h4>
</div>

<p class="card-summary">CLIP text/image encoder from "Learning Transferable Visual Models From Natural Language Supervision" trained on 400M text-image pairs</p>

<p class="tags">Classification,Logits,Embeddings,PyTorch,Clip,Zero-shot</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,Cityscapes,TensorFlow,Deeplabv3>

<div class="card tutorials-card" link=models.html#deeplabv3-cityscapes-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>deeplabv3-cityscapes-tf</h4>
</div>

<p class="card-summary">DeepLabv3+ semantic segmentation model from "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation" with Xception backbone trained on the Cityscapes dataset</p>

<p class="tags">Segmentation,Cityscapes,TensorFlow,Deeplabv3</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,Cityscapes,TensorFlow,Deeplabv3>

<div class="card tutorials-card" link=models.html#deeplabv3-mnv2-cityscapes-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>deeplabv3-mnv2-cityscapes-tf</h4>
</div>

<p class="card-summary">DeepLabv3+ semantic segmentation model from "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation" with MobileNetV2 backbone trained on the Cityscapes dataset</p>

<p class="tags">Segmentation,Cityscapes,TensorFlow,Deeplabv3</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,Coco,PyTorch,Resnet,Deeplabv3>

<div class="card tutorials-card" link=models.html#deeplabv3-resnet101-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>deeplabv3-resnet101-coco-torch</h4>
</div>

<p class="card-summary">DeepLabV3 model from "Rethinking Atrous Convolution for Semantic Image Segmentation" with ResNet-101 backbone trained on COCO</p>

<p class="tags">Segmentation,Coco,PyTorch,Resnet,Deeplabv3</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,Coco,PyTorch,Resnet,Deeplabv3>

<div class="card tutorials-card" link=models.html#deeplabv3-resnet50-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>deeplabv3-resnet50-coco-torch</h4>
</div>

<p class="card-summary">DeepLabV3 model from "Rethinking Atrous Convolution for Semantic Image Segmentation" with ResNet-50 backbone trained on COCO</p>

<p class="tags">Segmentation,Coco,PyTorch,Resnet,Deeplabv3</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Densenet>

<div class="card tutorials-card" link=models.html#densenet121-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>densenet121-imagenet-torch</h4>
</div>

<p class="card-summary">Densenet-121 model from "Densely Connected Convolutional Networks" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Densenet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Densenet>

<div class="card tutorials-card" link=models.html#densenet161-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>densenet161-imagenet-torch</h4>
</div>

<p class="card-summary">Densenet-161 model from "Densely Connected Convolutional Networks" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Densenet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Densenet>

<div class="card tutorials-card" link=models.html#densenet169-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>densenet169-imagenet-torch</h4>
</div>

<p class="card-summary">Densenet-169 model from "Densely Connected Convolutional Networks" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Densenet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Densenet>

<div class="card tutorials-card" link=models.html#densenet201-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>densenet201-imagenet-torch</h4>
</div>

<p class="card-summary">Densenet-201 model from "Densely Connected Convolutional Networks" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Densenet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Depth,PyTorch,Transformers>

<div class="card tutorials-card" link=models.html#depth-estimation-transformer-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>depth-estimation-transformer-torch</h4>
</div>

<p class="card-summary">Hugging Face Transformers model for monocular depth estimation</p>

<p class="tags">Depth,PyTorch,Transformers</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Logits,Embeddings,PyTorch,Transformers>

<div class="card tutorials-card" link=models.html#detection-transformer-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>detection-transformer-torch</h4>
</div>

<p class="card-summary">Hugging Face Transformers model for object detection</p>

<p class="tags">Detection,Logits,Embeddings,PyTorch,Transformers</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Embeddings,PyTorch,Dinov2>

<div class="card tutorials-card" link=models.html#dinov2-vitb14-reg-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>dinov2-vitb14-reg-torch</h4>
</div>

<p class="card-summary">DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-B/14 distilled</p>

<p class="tags">Embeddings,PyTorch,Dinov2</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Embeddings,PyTorch,Dinov2>

<div class="card tutorials-card" link=models.html#dinov2-vitb14-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>dinov2-vitb14-torch</h4>
</div>

<p class="card-summary">DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-B/14 distilled</p>

<p class="tags">Embeddings,PyTorch,Dinov2</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Embeddings,PyTorch,Dinov2>

<div class="card tutorials-card" link=models.html#dinov2-vitg14-reg-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>dinov2-vitg14-reg-torch</h4>
</div>

<p class="card-summary">DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-g/14</p>

<p class="tags">Embeddings,PyTorch,Dinov2</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Embeddings,PyTorch,Dinov2>

<div class="card tutorials-card" link=models.html#dinov2-vitg14-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>dinov2-vitg14-torch</h4>
</div>

<p class="card-summary">DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-g/14</p>

<p class="tags">Embeddings,PyTorch,Dinov2</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Embeddings,PyTorch,Dinov2>

<div class="card tutorials-card" link=models.html#dinov2-vitl14-reg-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>dinov2-vitl14-reg-torch</h4>
</div>

<p class="card-summary">DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-L/14 distilled</p>

<p class="tags">Embeddings,PyTorch,Dinov2</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Embeddings,PyTorch,Dinov2>

<div class="card tutorials-card" link=models.html#dinov2-vitl14-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>dinov2-vitl14-torch</h4>
</div>

<p class="card-summary">DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-L/14 distilled</p>

<p class="tags">Embeddings,PyTorch,Dinov2</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Embeddings,PyTorch,Dinov2>

<div class="card tutorials-card" link=models.html#dinov2-vits14-reg-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>dinov2-vits14-reg-torch</h4>
</div>

<p class="card-summary">DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-S/14 distilled</p>

<p class="tags">Embeddings,PyTorch,Dinov2</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Embeddings,PyTorch,Dinov2>

<div class="card tutorials-card" link=models.html#dinov2-vits14-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>dinov2-vits14-torch</h4>
</div>

<p class="card-summary">DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-S/14 distilled</p>

<p class="tags">Embeddings,PyTorch,Dinov2</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-2,Efficientdet>

<div class="card tutorials-card" link=models.html#efficientdet-d0-512-coco-tf2>

<div class="card-body">

<div class="card-title-container">
    <h4>efficientdet-d0-512-coco-tf2</h4>
</div>

<p class="card-summary">EfficientDet-D0 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO resized to 512x512</p>

<p class="tags">Detection,Coco,TensorFlow-2,Efficientdet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-1,Efficientdet>

<div class="card tutorials-card" link=models.html#efficientdet-d0-coco-tf1>

<div class="card-body">

<div class="card-title-container">
    <h4>efficientdet-d0-coco-tf1</h4>
</div>

<p class="card-summary">EfficientDet-D0 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow-1,Efficientdet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-2,Efficientdet>

<div class="card tutorials-card" link=models.html#efficientdet-d1-640-coco-tf2>

<div class="card-body">

<div class="card-title-container">
    <h4>efficientdet-d1-640-coco-tf2</h4>
</div>

<p class="card-summary">EfficientDet-D1 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO resized to 640x640</p>

<p class="tags">Detection,Coco,TensorFlow-2,Efficientdet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-1,Efficientdet>

<div class="card tutorials-card" link=models.html#efficientdet-d1-coco-tf1>

<div class="card-body">

<div class="card-title-container">
    <h4>efficientdet-d1-coco-tf1</h4>
</div>

<p class="card-summary">EfficientDet-D1 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow-1,Efficientdet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-2,Efficientdet>

<div class="card tutorials-card" link=models.html#efficientdet-d2-768-coco-tf2>

<div class="card-body">

<div class="card-title-container">
    <h4>efficientdet-d2-768-coco-tf2</h4>
</div>

<p class="card-summary">EfficientDet-D2 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO resized to 768x768</p>

<p class="tags">Detection,Coco,TensorFlow-2,Efficientdet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-1,Efficientdet>

<div class="card tutorials-card" link=models.html#efficientdet-d2-coco-tf1>

<div class="card-body">

<div class="card-title-container">
    <h4>efficientdet-d2-coco-tf1</h4>
</div>

<p class="card-summary">EfficientDet-D2 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow-1,Efficientdet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-2,Efficientdet>

<div class="card tutorials-card" link=models.html#efficientdet-d3-896-coco-tf2>

<div class="card-body">

<div class="card-title-container">
    <h4>efficientdet-d3-896-coco-tf2</h4>
</div>

<p class="card-summary">EfficientDet-D3 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO resized to 896x896</p>

<p class="tags">Detection,Coco,TensorFlow-2,Efficientdet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-1,Efficientdet>

<div class="card tutorials-card" link=models.html#efficientdet-d3-coco-tf1>

<div class="card-body">

<div class="card-title-container">
    <h4>efficientdet-d3-coco-tf1</h4>
</div>

<p class="card-summary">EfficientDet-D3 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow-1,Efficientdet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-2,Efficientdet>

<div class="card tutorials-card" link=models.html#efficientdet-d4-1024-coco-tf2>

<div class="card-body">

<div class="card-title-container">
    <h4>efficientdet-d4-1024-coco-tf2</h4>
</div>

<p class="card-summary">EfficientDet-D4 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO resized to 1024x1024</p>

<p class="tags">Detection,Coco,TensorFlow-2,Efficientdet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-1,Efficientdet>

<div class="card tutorials-card" link=models.html#efficientdet-d4-coco-tf1>

<div class="card-body">

<div class="card-title-container">
    <h4>efficientdet-d4-coco-tf1</h4>
</div>

<p class="card-summary">EfficientDet-D4 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow-1,Efficientdet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-2,Efficientdet>

<div class="card tutorials-card" link=models.html#efficientdet-d5-1280-coco-tf2>

<div class="card-body">

<div class="card-title-container">
    <h4>efficientdet-d5-1280-coco-tf2</h4>
</div>

<p class="card-summary">EfficientDet-D5 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO resized to 1280x1280</p>

<p class="tags">Detection,Coco,TensorFlow-2,Efficientdet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-1,Efficientdet>

<div class="card tutorials-card" link=models.html#efficientdet-d5-coco-tf1>

<div class="card-body">

<div class="card-title-container">
    <h4>efficientdet-d5-coco-tf1</h4>
</div>

<p class="card-summary">EfficientDet-D5 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow-1,Efficientdet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-2,Efficientdet>

<div class="card tutorials-card" link=models.html#efficientdet-d6-1280-coco-tf2>

<div class="card-body">

<div class="card-title-container">
    <h4>efficientdet-d6-1280-coco-tf2</h4>
</div>

<p class="card-summary">EfficientDet-D6 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO resized to 1280x1280</p>

<p class="tags">Detection,Coco,TensorFlow-2,Efficientdet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-1,Efficientdet>

<div class="card tutorials-card" link=models.html#efficientdet-d6-coco-tf1>

<div class="card-body">

<div class="card-title-container">
    <h4>efficientdet-d6-coco-tf1</h4>
</div>

<p class="card-summary">EfficientDet-D6 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow-1,Efficientdet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-2,Efficientdet>

<div class="card tutorials-card" link=models.html#efficientdet-d7-1536-coco-tf2>

<div class="card-body">

<div class="card-title-container">
    <h4>efficientdet-d7-1536-coco-tf2</h4>
</div>

<p class="card-summary">EfficientDet-D7 model from "EfficientDet: Scalable and Efficient Object Detection" trained on COCO resized to 1536x1536</p>

<p class="tags">Detection,Coco,TensorFlow-2,Efficientdet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow,Faster-rcnn,Inception,Resnet>

<div class="card tutorials-card" link=models.html#faster-rcnn-inception-resnet-atrous-v2-coco-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>faster-rcnn-inception-resnet-atrous-v2-coco-tf</h4>
</div>

<p class="card-summary">Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" atrous version with Inception backbone trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow,Faster-rcnn,Inception,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow,Faster-rcnn,Inception,Resnet>

<div class="card tutorials-card" link=models.html#faster-rcnn-inception-resnet-atrous-v2-lowproposals-coco-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>faster-rcnn-inception-resnet-atrous-v2-lowproposals-coco-tf</h4>
</div>

<p class="card-summary">Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" atrous version with low-proposals and Inception backbone trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow,Faster-rcnn,Inception,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow,Faster-rcnn,Inception>

<div class="card tutorials-card" link=models.html#faster-rcnn-inception-v2-coco-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>faster-rcnn-inception-v2-coco-tf</h4>
</div>

<p class="card-summary">Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" with Inception v2 backbone trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow,Faster-rcnn,Inception</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow,Faster-rcnn>

<div class="card tutorials-card" link=models.html#faster-rcnn-nas-coco-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>faster-rcnn-nas-coco-tf</h4>
</div>

<p class="card-summary">Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" with NAS-net backbone trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow,Faster-rcnn</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow,Faster-rcnn>

<div class="card tutorials-card" link=models.html#faster-rcnn-nas-lowproposals-coco-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>faster-rcnn-nas-lowproposals-coco-tf</h4>
</div>

<p class="card-summary">Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" with low-proposals and NAS-net backbone trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow,Faster-rcnn</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow,Faster-rcnn,Resnet>

<div class="card tutorials-card" link=models.html#faster-rcnn-resnet101-coco-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>faster-rcnn-resnet101-coco-tf</h4>
</div>

<p class="card-summary">Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" with ResNet-101 backbone trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow,Faster-rcnn,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow,Faster-rcnn,Resnet>

<div class="card tutorials-card" link=models.html#faster-rcnn-resnet101-lowproposals-coco-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>faster-rcnn-resnet101-lowproposals-coco-tf</h4>
</div>

<p class="card-summary">Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" with low-proposals and ResNet-101 backbone trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow,Faster-rcnn,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow,Faster-rcnn,Resnet>

<div class="card tutorials-card" link=models.html#faster-rcnn-resnet50-coco-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>faster-rcnn-resnet50-coco-tf</h4>
</div>

<p class="card-summary">Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" with ResNet-50 backbone trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow,Faster-rcnn,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Faster-rcnn,Resnet>

<div class="card tutorials-card" link=models.html#faster-rcnn-resnet50-fpn-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>faster-rcnn-resnet50-fpn-coco-torch</h4>
</div>

<p class="card-summary">Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" with ResNet-50 FPN backbone trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Faster-rcnn,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow,Faster-rcnn,Resnet>

<div class="card tutorials-card" link=models.html#faster-rcnn-resnet50-lowproposals-coco-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>faster-rcnn-resnet50-lowproposals-coco-tf</h4>
</div>

<p class="card-summary">Faster R-CNN model from "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" with low-proposals and ResNet-50 backbone trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow,Faster-rcnn,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,Coco,PyTorch,Fcn,Resnet>

<div class="card tutorials-card" link=models.html#fcn-resnet101-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>fcn-resnet101-coco-torch</h4>
</div>

<p class="card-summary">FCN model from "Fully Convolutional Networks for Semantic Segmentation" with ResNet-101 backbone trained on COCO</p>

<p class="tags">Segmentation,Coco,PyTorch,Fcn,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,Coco,PyTorch,Fcn,Resnet>

<div class="card tutorials-card" link=models.html#fcn-resnet50-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>fcn-resnet50-coco-torch</h4>
</div>

<p class="card-summary">FCN model from "Fully Convolutional Networks for Semantic Segmentation" with ResNet-50 backbone trained on COCO</p>

<p class="tags">Segmentation,Coco,PyTorch,Fcn,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Googlenet>

<div class="card tutorials-card" link=models.html#googlenet-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>googlenet-imagenet-torch</h4>
</div>

<p class="card-summary">GoogLeNet (Inception v1) model from "Going Deeper with Convolutions" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Googlenet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,TensorFlow-1,Inception,Resnet>

<div class="card tutorials-card" link=models.html#inception-resnet-v2-imagenet-tf1>

<div class="card-body">

<div class="card-title-container">
    <h4>inception-resnet-v2-imagenet-tf1</h4>
</div>

<p class="card-summary">Inception v2 model from "Rethinking the Inception Architecture for Computer Vision" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,TensorFlow-1,Inception,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Inception>

<div class="card tutorials-card" link=models.html#inception-v3-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>inception-v3-imagenet-torch</h4>
</div>

<p class="card-summary">Inception v3 model from "Rethinking the Inception Architecture for Computer Vision" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Inception</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,TensorFlow-1,Inception>

<div class="card tutorials-card" link=models.html#inception-v4-imagenet-tf1>

<div class="card-body">

<div class="card-title-container">
    <h4>inception-v4-imagenet-tf1</h4>
</div>

<p class="card-summary">Inception v4 model from "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,TensorFlow-1,Inception</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Keypoints,Coco,PyTorch,Keypoint-rcnn,Resnet>

<div class="card tutorials-card" link=models.html#keypoint-rcnn-resnet50-fpn-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>keypoint-rcnn-resnet50-fpn-coco-torch</h4>
</div>

<p class="card-summary">Keypoint R-CNN model from "Mask R-CNN" with ResNet-50 FPN backbone trained on COCO</p>

<p class="tags">Keypoints,Coco,PyTorch,Keypoint-rcnn,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Instances,Coco,TensorFlow,Mask-rcnn,Inception,Resnet>

<div class="card tutorials-card" link=models.html#mask-rcnn-inception-resnet-v2-atrous-coco-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>mask-rcnn-inception-resnet-v2-atrous-coco-tf</h4>
</div>

<p class="card-summary">Mask R-CNN model from "Mask R-CNN" atrous version with Inception backbone trained on COCO</p>

<p class="tags">Instances,Coco,TensorFlow,Mask-rcnn,Inception,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Instances,Coco,TensorFlow,Mask-rcnn,Inception>

<div class="card tutorials-card" link=models.html#mask-rcnn-inception-v2-coco-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>mask-rcnn-inception-v2-coco-tf</h4>
</div>

<p class="card-summary">Mask R-CNN model from "Mask R-CNN" with Inception backbone trained on COCO</p>

<p class="tags">Instances,Coco,TensorFlow,Mask-rcnn,Inception</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Instances,Coco,TensorFlow,Mask-rcnn,Resnet>

<div class="card tutorials-card" link=models.html#mask-rcnn-resnet101-atrous-coco-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>mask-rcnn-resnet101-atrous-coco-tf</h4>
</div>

<p class="card-summary">Mask R-CNN model from "Mask R-CNN" atrous version with ResNet-101 backbone trained on COCO</p>

<p class="tags">Instances,Coco,TensorFlow,Mask-rcnn,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Instances,Coco,TensorFlow,Mask-rcnn,Resnet>

<div class="card tutorials-card" link=models.html#mask-rcnn-resnet50-atrous-coco-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>mask-rcnn-resnet50-atrous-coco-tf</h4>
</div>

<p class="card-summary">Mask R-CNN model from "Mask R-CNN" atrous version with ResNet-50 backbone trained on COCO</p>

<p class="tags">Instances,Coco,TensorFlow,Mask-rcnn,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Instances,Coco,PyTorch,Mask-rcnn,Resnet>

<div class="card tutorials-card" link=models.html#mask-rcnn-resnet50-fpn-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>mask-rcnn-resnet50-fpn-coco-torch</h4>
</div>

<p class="card-summary">Mask R-CNN model from "Mask R-CNN" with ResNet-50 FPN backbone trained on COCO</p>

<p class="tags">Instances,Coco,PyTorch,Mask-rcnn,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,PyTorch,Zero-shot,Video,Med-sam>

<div class="card tutorials-card" link=models.html#med-sam-2-video-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>med-sam-2-video-torch</h4>
</div>

<p class="card-summary">Fine-tuned SAM2-hiera-tiny model from "Medical SAM 2 - Segment Medical Images as Video via Segment Anything Model 2"</p>

<p class="tags">Segment-anything,PyTorch,Zero-shot,Video,Med-sam</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Mnasnet>

<div class="card tutorials-card" link=models.html#mnasnet0-5-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>mnasnet0.5-imagenet-torch</h4>
</div>

<p class="card-summary">MNASNet model from from "MnasNet: Platform-Aware Neural Architecture Search for Mobile" with depth multiplier of 0.5 trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Mnasnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Mnasnet>

<div class="card tutorials-card" link=models.html#mnasnet1-0-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>mnasnet1.0-imagenet-torch</h4>
</div>

<p class="card-summary">MNASNet model from "MnasNet: Platform-Aware Neural Architecture Search for Mobile" with depth multiplier of 1.0 trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Mnasnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,TensorFlow-1,Mobilenet>

<div class="card tutorials-card" link=models.html#mobilenet-v2-imagenet-tf1>

<div class="card-body">

<div class="card-title-container">
    <h4>mobilenet-v2-imagenet-tf1</h4>
</div>

<p class="card-summary">MobileNetV2 model from "MobileNetV2: Inverted Residuals and Linear Bottlenecks" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,TensorFlow-1,Mobilenet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Mobilenet>

<div class="card tutorials-card" link=models.html#mobilenet-v2-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>mobilenet-v2-imagenet-torch</h4>
</div>

<p class="card-summary">MobileNetV2 model from "MobileNetV2: Inverted Residuals and Linear Bottlenecks" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Mobilenet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Logits,Embeddings,PyTorch,Clip,Zero-shot>

<div class="card tutorials-card" link=models.html#open-clip-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>open-clip-torch</h4>
</div>

<p class="card-summary">OPEN CLIP text/image encoder from "Learning Transferable Visual Models From Natural Language Supervision" trained on 400M text-image pairs</p>

<p class="tags">Classification,Logits,Embeddings,PyTorch,Clip,Zero-shot</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,TensorFlow-1,Resnet>

<div class="card tutorials-card" link=models.html#resnet-v1-50-imagenet-tf1>

<div class="card-body">

<div class="card-title-container">
    <h4>resnet-v1-50-imagenet-tf1</h4>
</div>

<p class="card-summary">ResNet-50 v1 model from "Deep Residual Learning for Image Recognition" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,TensorFlow-1,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,TensorFlow-1,Resnet>

<div class="card tutorials-card" link=models.html#resnet-v2-50-imagenet-tf1>

<div class="card-body">

<div class="card-title-container">
    <h4>resnet-v2-50-imagenet-tf1</h4>
</div>

<p class="card-summary">ResNet-50 v2 model from "Deep Residual Learning for Image Recognition" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,TensorFlow-1,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Resnet>

<div class="card tutorials-card" link=models.html#resnet101-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>resnet101-imagenet-torch</h4>
</div>

<p class="card-summary">ResNet-101 model from "Deep Residual Learning for Image Recognition" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Resnet>

<div class="card tutorials-card" link=models.html#resnet152-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>resnet152-imagenet-torch</h4>
</div>

<p class="card-summary">ResNet-152 model from "Deep Residual Learning for Image Recognition" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Resnet>

<div class="card tutorials-card" link=models.html#resnet18-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>resnet18-imagenet-torch</h4>
</div>

<p class="card-summary">ResNet-18 model from "Deep Residual Learning for Image Recognition" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Resnet>

<div class="card tutorials-card" link=models.html#resnet34-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>resnet34-imagenet-torch</h4>
</div>

<p class="card-summary">ResNet-34 model from "Deep Residual Learning for Image Recognition" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Resnet>

<div class="card tutorials-card" link=models.html#resnet50-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>resnet50-imagenet-torch</h4>
</div>

<p class="card-summary">ResNet-50 model from "Deep Residual Learning for Image Recognition" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Resnext>

<div class="card tutorials-card" link=models.html#resnext101-32x8d-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>resnext101-32x8d-imagenet-torch</h4>
</div>

<p class="card-summary">ResNeXt-101 32x8d model from "Aggregated Residual Transformations for Deep Neural Networks" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Resnext</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Resnext>

<div class="card tutorials-card" link=models.html#resnext50-32x4d-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>resnext50-32x4d-imagenet-torch</h4>
</div>

<p class="card-summary">ResNeXt-50 32x4d model from "Aggregated Residual Transformations for Deep Neural Networks" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Resnext</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Retinanet,Resnet>

<div class="card tutorials-card" link=models.html#retinanet-resnet50-fpn-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>retinanet-resnet50-fpn-coco-torch</h4>
</div>

<p class="card-summary">RetinaNet model from "Focal Loss for Dense Object Detection" with ResNet-50 FPN backbone trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Retinanet,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow,Rfcn,Resnet>

<div class="card tutorials-card" link=models.html#rfcn-resnet101-coco-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>rfcn-resnet101-coco-tf</h4>
</div>

<p class="card-summary">R-FCN object detection model from "R-FCN: Object Detection via Region-based Fully Convolutional Networks" with ResNet-101 backbone trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow,Rfcn,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Transformer,Rtdetr>

<div class="card tutorials-card" link=models.html#rtdetr-l-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>rtdetr-l-coco-torch</h4>
</div>

<p class="card-summary">RT-DETR-l model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Transformer,Rtdetr</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Transformer,Rtdetr>

<div class="card tutorials-card" link=models.html#rtdetr-x-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>rtdetr-x-coco-torch</h4>
</div>

<p class="card-summary">RT-DETR-x model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Transformer,Rtdetr</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,PyTorch,Zero-shot>

<div class="card tutorials-card" link=models.html#segment-anything-2-hiera-base-plus-image-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-2-hiera-base-plus-image-torch</h4>
</div>

<p class="card-summary">Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"</p>

<p class="tags">Segment-anything,PyTorch,Zero-shot</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,PyTorch,Zero-shot,Video>

<div class="card tutorials-card" link=models.html#segment-anything-2-hiera-base-plus-video-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-2-hiera-base-plus-video-torch</h4>
</div>

<p class="card-summary">Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"</p>

<p class="tags">Segment-anything,PyTorch,Zero-shot,Video</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,PyTorch,Zero-shot>

<div class="card tutorials-card" link=models.html#segment-anything-2-hiera-large-image-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-2-hiera-large-image-torch</h4>
</div>

<p class="card-summary">Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"</p>

<p class="tags">Segment-anything,PyTorch,Zero-shot</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,PyTorch,Zero-shot,Video>

<div class="card tutorials-card" link=models.html#segment-anything-2-hiera-large-video-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-2-hiera-large-video-torch</h4>
</div>

<p class="card-summary">Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"</p>

<p class="tags">Segment-anything,PyTorch,Zero-shot,Video</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,PyTorch,Zero-shot>

<div class="card tutorials-card" link=models.html#segment-anything-2-hiera-small-image-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-2-hiera-small-image-torch</h4>
</div>

<p class="card-summary">Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"</p>

<p class="tags">Segment-anything,PyTorch,Zero-shot</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,PyTorch,Zero-shot,Video>

<div class="card tutorials-card" link=models.html#segment-anything-2-hiera-small-video-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-2-hiera-small-video-torch</h4>
</div>

<p class="card-summary">Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"</p>

<p class="tags">Segment-anything,PyTorch,Zero-shot,Video</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,PyTorch,Zero-shot>

<div class="card tutorials-card" link=models.html#segment-anything-2-hiera-tiny-image-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-2-hiera-tiny-image-torch</h4>
</div>

<p class="card-summary">Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"</p>

<p class="tags">Segment-anything,PyTorch,Zero-shot</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,PyTorch,Zero-shot,Video>

<div class="card tutorials-card" link=models.html#segment-anything-2-hiera-tiny-video-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-2-hiera-tiny-video-torch</h4>
</div>

<p class="card-summary">Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"</p>

<p class="tags">Segment-anything,PyTorch,Zero-shot,Video</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,PyTorch,Zero-shot>

<div class="card tutorials-card" link=models.html#segment-anything-2-1-hiera-base-plus-image-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-2.1-hiera-base-plus-image-torch</h4>
</div>

<p class="card-summary">Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"</p>

<p class="tags">Segment-anything,PyTorch,Zero-shot</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,PyTorch,Zero-shot,Video>

<div class="card tutorials-card" link=models.html#segment-anything-2-1-hiera-base-plus-video-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-2.1-hiera-base-plus-video-torch</h4>
</div>

<p class="card-summary">Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"</p>

<p class="tags">Segment-anything,PyTorch,Zero-shot,Video</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,PyTorch,Zero-shot>

<div class="card tutorials-card" link=models.html#segment-anything-2-1-hiera-large-image-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-2.1-hiera-large-image-torch</h4>
</div>

<p class="card-summary">Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"</p>

<p class="tags">Segment-anything,PyTorch,Zero-shot</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,PyTorch,Zero-shot,Video>

<div class="card tutorials-card" link=models.html#segment-anything-2-1-hiera-large-video-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-2.1-hiera-large-video-torch</h4>
</div>

<p class="card-summary">Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"</p>

<p class="tags">Segment-anything,PyTorch,Zero-shot,Video</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,PyTorch,Zero-shot>

<div class="card tutorials-card" link=models.html#segment-anything-2-1-hiera-small-image-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-2.1-hiera-small-image-torch</h4>
</div>

<p class="card-summary">Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"</p>

<p class="tags">Segment-anything,PyTorch,Zero-shot</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,PyTorch,Zero-shot,Video>

<div class="card tutorials-card" link=models.html#segment-anything-2-1-hiera-small-video-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-2.1-hiera-small-video-torch</h4>
</div>

<p class="card-summary">Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"</p>

<p class="tags">Segment-anything,PyTorch,Zero-shot,Video</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,PyTorch,Zero-shot>

<div class="card tutorials-card" link=models.html#segment-anything-2-1-hiera-tiny-image-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-2.1-hiera-tiny-image-torch</h4>
</div>

<p class="card-summary">Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"</p>

<p class="tags">Segment-anything,PyTorch,Zero-shot</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,PyTorch,Zero-shot,Video>

<div class="card tutorials-card" link=models.html#segment-anything-2-1-hiera-tiny-video-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-2.1-hiera-tiny-video-torch</h4>
</div>

<p class="card-summary">Segment Anything Model 2 (SAM2) from "SAM2: Segment Anything in Images and Videos"</p>

<p class="tags">Segment-anything,PyTorch,Zero-shot,Video</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,Sa-1b,PyTorch,Zero-shot>

<div class="card tutorials-card" link=models.html#segment-anything-vitb-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-vitb-torch</h4>
</div>

<p class="card-summary">Segment Anything Model (SAM) from "Segment Anything" with ViT-B/16 backbone trained on SA-1B</p>

<p class="tags">Segment-anything,Sa-1b,PyTorch,Zero-shot</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,Sa-1b,PyTorch,Zero-shot>

<div class="card tutorials-card" link=models.html#segment-anything-vith-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-vith-torch</h4>
</div>

<p class="card-summary">Segment Anything Model (SAM) from "Segment Anything" with ViT-H/16 backbone trained on SA-1B</p>

<p class="tags">Segment-anything,Sa-1b,PyTorch,Zero-shot</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segment-anything,Sa-1b,PyTorch,Zero-shot>

<div class="card tutorials-card" link=models.html#segment-anything-vitl-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segment-anything-vitl-torch</h4>
</div>

<p class="card-summary">Segment Anything Model (SAM) from "Segment Anything" with ViT-L/16 backbone trained on SA-1B</p>

<p class="tags">Segment-anything,Sa-1b,PyTorch,Zero-shot</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,PyTorch,Transformers>

<div class="card tutorials-card" link=models.html#segmentation-transformer-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>segmentation-transformer-torch</h4>
</div>

<p class="card-summary">Hugging Face Transformers model for semantic segmentation</p>

<p class="tags">Segmentation,PyTorch,Transformers</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Shufflenet>

<div class="card tutorials-card" link=models.html#shufflenetv2-0-5x-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>shufflenetv2-0.5x-imagenet-torch</h4>
</div>

<p class="card-summary">ShuffleNetV2 model from "ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design" with 0.5x output channels trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Shufflenet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Shufflenet>

<div class="card tutorials-card" link=models.html#shufflenetv2-1-0x-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>shufflenetv2-1.0x-imagenet-torch</h4>
</div>

<p class="card-summary">ShuffleNetV2 model from "ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design" with 1.0x output channels trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Shufflenet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Imagenet,PyTorch,Squeezenet>

<div class="card tutorials-card" link=models.html#squeezenet-1-1-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>squeezenet-1.1-imagenet-torch</h4>
</div>

<p class="card-summary">SqueezeNet 1.1 model from "the official SqueezeNet repo" trained on ImageNet</p>

<p class="tags">Classification,Imagenet,PyTorch,Squeezenet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Imagenet,PyTorch,Squeezenet>

<div class="card tutorials-card" link=models.html#squeezenet-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>squeezenet-imagenet-torch</h4>
</div>

<p class="card-summary">SqueezeNet model from "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and" trained on ImageNet</p>

<p class="tags">Classification,Imagenet,PyTorch,Squeezenet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow,Ssd,Inception>

<div class="card tutorials-card" link=models.html#ssd-inception-v2-coco-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>ssd-inception-v2-coco-tf</h4>
</div>

<p class="card-summary">Inception Single Shot Detector model from "SSD: Single Shot MultiBox Detector" trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow,Ssd,Inception</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow,Ssd,Mobilenet>

<div class="card tutorials-card" link=models.html#ssd-mobilenet-v1-coco-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>ssd-mobilenet-v1-coco-tf</h4>
</div>

<p class="card-summary">Single Shot Detector model from "SSD: Single Shot MultiBox Detector" with MobileNetV1 backbone trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow,Ssd,Mobilenet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-2,Ssd,Mobilenet>

<div class="card tutorials-card" link=models.html#ssd-mobilenet-v1-fpn-640-coco17>

<div class="card-body">

<div class="card-title-container">
    <h4>ssd-mobilenet-v1-fpn-640-coco17</h4>
</div>

<p class="card-summary">MobileNetV1 model from "MobileNetV2: Inverted Residuals and Linear Bottlenecks" resized to 640x640</p>

<p class="tags">Detection,Coco,TensorFlow-2,Ssd,Mobilenet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow,Ssd,Mobilenet>

<div class="card tutorials-card" link=models.html#ssd-mobilenet-v1-fpn-coco-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>ssd-mobilenet-v1-fpn-coco-tf</h4>
</div>

<p class="card-summary">FPN Single Shot Detector model from "SSD: Single Shot MultiBox Detector" with MobileNetV1 backbone trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow,Ssd,Mobilenet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-2,Ssd,Mobilenet>

<div class="card tutorials-card" link=models.html#ssd-mobilenet-v2-320-coco17>

<div class="card-body">

<div class="card-title-container">
    <h4>ssd-mobilenet-v2-320-coco17</h4>
</div>

<p class="card-summary">MobileNetV2 model from "MobileNetV2: Inverted Residuals and Linear Bottlenecks" resized to 320x320</p>

<p class="tags">Detection,Coco,TensorFlow-2,Ssd,Mobilenet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow,Ssd,Resnet>

<div class="card tutorials-card" link=models.html#ssd-resnet50-fpn-coco-tf>

<div class="card-body">

<div class="card-title-container">
    <h4>ssd-resnet50-fpn-coco-tf</h4>
</div>

<p class="card-summary">FPN Single Shot Detector model from "SSD: Single Shot MultiBox Detector" with ResNet-50 backbone trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow,Ssd,Resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg>

<div class="card tutorials-card" link=models.html#vgg11-bn-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>vgg11-bn-imagenet-torch</h4>
</div>

<p class="card-summary">VGG-11 model from "Very Deep Convolutional Networks for Large-Scale Image Recognition" with batch normalization trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg>

<div class="card tutorials-card" link=models.html#vgg11-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>vgg11-imagenet-torch</h4>
</div>

<p class="card-summary">VGG-11 model from "Very Deep Convolutional Networks for Large-Scale Image Recognition" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg>

<div class="card tutorials-card" link=models.html#vgg13-bn-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>vgg13-bn-imagenet-torch</h4>
</div>

<p class="card-summary">VGG-13 model from "Very Deep Convolutional Networks for Large-Scale Image Recognition" with batch normalization trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg>

<div class="card tutorials-card" link=models.html#vgg13-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>vgg13-imagenet-torch</h4>
</div>

<p class="card-summary">VGG-13 model from "Very Deep Convolutional Networks for Large-Scale Image Recognition" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg>

<div class="card tutorials-card" link=models.html#vgg16-bn-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>vgg16-bn-imagenet-torch</h4>
</div>

<p class="card-summary">VGG-16 model from "Very Deep Convolutional Networks for Large-Scale Image Recognition" with batch normalization trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,TensorFlow-1,Vgg>

<div class="card tutorials-card" link=models.html#vgg16-imagenet-tf1>

<div class="card-body">

<div class="card-title-container">
    <h4>vgg16-imagenet-tf1</h4>
</div>

<p class="card-summary">VGG-16 model from "Very Deep Convolutional Networks for Large-Scale Image Recognition" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,TensorFlow-1,Vgg</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg>

<div class="card tutorials-card" link=models.html#vgg16-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>vgg16-imagenet-torch</h4>
</div>

<p class="card-summary">VGG-16 model from "Very Deep Convolutional Networks for Large-Scale Image Recognition" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg>

<div class="card tutorials-card" link=models.html#vgg19-bn-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>vgg19-bn-imagenet-torch</h4>
</div>

<p class="card-summary">VGG-19 model from "Very Deep Convolutional Networks for Large-Scale Image Recognition" with batch normalization trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg>

<div class="card tutorials-card" link=models.html#vgg19-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>vgg19-imagenet-torch</h4>
</div>

<p class="card-summary">VGG-19 model from "Very Deep Convolutional Networks for Large-Scale Image Recognition" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Vgg</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Wide-resnet>

<div class="card tutorials-card" link=models.html#wide-resnet101-2-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>wide-resnet101-2-imagenet-torch</h4>
</div>

<p class="card-summary">Wide ResNet-101-2 model from "Wide Residual Networks" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Wide-resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Embeddings,Logits,Imagenet,PyTorch,Wide-resnet>

<div class="card tutorials-card" link=models.html#wide-resnet50-2-imagenet-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>wide-resnet50-2-imagenet-torch</h4>
</div>

<p class="card-summary">Wide ResNet-50-2 model from "Wide Residual Networks" trained on ImageNet</p>

<p class="tags">Classification,Embeddings,Logits,Imagenet,PyTorch,Wide-resnet</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolo-nas-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolo-nas-torch</h4>
</div>

<p class="card-summary">YOLO-NAS is an open-source training library for advanced computer vision models. It specializes in accuracy and efficiency, supporting tasks like object detection</p>

<p class="tags">Detection,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,TensorFlow-1,Yolo>

<div class="card tutorials-card" link=models.html#yolo-v2-coco-tf1>

<div class="card-body">

<div class="card-title-container">
    <h4>yolo-v2-coco-tf1</h4>
</div>

<p class="card-summary">YOLOv2 model from "YOLO9000: Better, Faster, Stronger" trained on COCO</p>

<p class="tags">Detection,Coco,TensorFlow-1,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolo11l-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolo11l-coco-torch</h4>
</div>

<p class="card-summary">YOLO11-L model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolo11l-seg-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolo11l-seg-coco-torch</h4>
</div>

<p class="card-summary">YOLO11-L Segmentation model trained on COCO</p>

<p class="tags">Segmentation,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolo11m-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolo11m-coco-torch</h4>
</div>

<p class="card-summary">YOLO11-M model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolo11m-seg-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolo11m-seg-coco-torch</h4>
</div>

<p class="card-summary">YOLO11-M Segmentation model trained on COCO</p>

<p class="tags">Segmentation,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolo11n-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolo11n-coco-torch</h4>
</div>

<p class="card-summary">YOLO11-N model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolo11n-seg-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolo11n-seg-coco-torch</h4>
</div>

<p class="card-summary">YOLO11-N Segmentation model trained on COCO</p>

<p class="tags">Segmentation,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolo11s-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolo11s-coco-torch</h4>
</div>

<p class="card-summary">YOLO11-S model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolo11s-seg-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolo11s-seg-coco-torch</h4>
</div>

<p class="card-summary">YOLO11-S Segmentation model trained on COCO</p>

<p class="tags">Segmentation,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolo11x-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolo11x-coco-torch</h4>
</div>

<p class="card-summary">YOLO11-X model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolo11x-seg-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolo11x-seg-coco-torch</h4>
</div>

<p class="card-summary">YOLO11-X Segmentation model trained on COCO</p>

<p class="tags">Segmentation,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov10l-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov10l-coco-torch</h4>
</div>

<p class="card-summary">YOLOv10-L model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov10m-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov10m-coco-torch</h4>
</div>

<p class="card-summary">YOLOv10-M model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov10n-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov10n-coco-torch</h4>
</div>

<p class="card-summary">YOLOv10-N model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov10s-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov10s-coco-torch</h4>
</div>

<p class="card-summary">YOLOv10-S model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov10x-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov10x-coco-torch</h4>
</div>

<p class="card-summary">YOLOv10-X model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov5l-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov5l-coco-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv5l model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov5m-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov5m-coco-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv5m model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov5n-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov5n-coco-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv5n model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov5s-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov5s-coco-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv5s model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov5x-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov5x-coco-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv5x model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov8l-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8l-coco-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv8l model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,PyTorch,Yolo,Polylines,Obb>

<div class="card tutorials-card" link=models.html#yolov8l-obb-dotav1-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8l-obb-dotav1-torch</h4>
</div>

<p class="card-summary">YOLOv8l Oriented Bounding Box model</p>

<p class="tags">Detection,PyTorch,Yolo,Polylines,Obb</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Oiv7,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov8l-oiv7-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8l-oiv7-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv8l model trained Open Images v7</p>

<p class="tags">Detection,Oiv7,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov8l-seg-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8l-seg-coco-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv8l Segmentation model trained on COCO</p>

<p class="tags">Segmentation,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,PyTorch,Yolo,Zero-shot>

<div class="card tutorials-card" link=models.html#yolov8l-world-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8l-world-torch</h4>
</div>

<p class="card-summary">YOLOv8l-World model</p>

<p class="tags">Detection,PyTorch,Yolo,Zero-shot</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov8m-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8m-coco-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv8m model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,PyTorch,Yolo,Polylines,Obb>

<div class="card tutorials-card" link=models.html#yolov8m-obb-dotav1-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8m-obb-dotav1-torch</h4>
</div>

<p class="card-summary">YOLOv8m Oriented Bounding Box model</p>

<p class="tags">Detection,PyTorch,Yolo,Polylines,Obb</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Oiv7,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov8m-oiv7-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8m-oiv7-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv8m model trained Open Images v7</p>

<p class="tags">Detection,Oiv7,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov8m-seg-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8m-seg-coco-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv8m Segmentation model trained on COCO</p>

<p class="tags">Segmentation,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,PyTorch,Yolo,Zero-shot>

<div class="card tutorials-card" link=models.html#yolov8m-world-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8m-world-torch</h4>
</div>

<p class="card-summary">YOLOv8m-World model</p>

<p class="tags">Detection,PyTorch,Yolo,Zero-shot</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov8n-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8n-coco-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv8n model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,PyTorch,Yolo,Polylines,Obb>

<div class="card tutorials-card" link=models.html#yolov8n-obb-dotav1-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8n-obb-dotav1-torch</h4>
</div>

<p class="card-summary">YOLOv8n Oriented Bounding Box model</p>

<p class="tags">Detection,PyTorch,Yolo,Polylines,Obb</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Oiv7,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov8n-oiv7-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8n-oiv7-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv8n model trained on Open Images v7</p>

<p class="tags">Detection,Oiv7,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov8n-seg-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8n-seg-coco-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv8n Segmentation model trained on COCO</p>

<p class="tags">Segmentation,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov8s-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8s-coco-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv8s model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,PyTorch,Yolo,Polylines,Obb>

<div class="card tutorials-card" link=models.html#yolov8s-obb-dotav1-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8s-obb-dotav1-torch</h4>
</div>

<p class="card-summary">YOLOv8s Oriented Bounding Box model</p>

<p class="tags">Detection,PyTorch,Yolo,Polylines,Obb</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Oiv7,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov8s-oiv7-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8s-oiv7-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv8s model trained on Open Images v7</p>

<p class="tags">Detection,Oiv7,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov8s-seg-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8s-seg-coco-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv8s Segmentation model trained on COCO</p>

<p class="tags">Segmentation,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,PyTorch,Yolo,Zero-shot>

<div class="card tutorials-card" link=models.html#yolov8s-world-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8s-world-torch</h4>
</div>

<p class="card-summary">YOLOv8s-World model</p>

<p class="tags">Detection,PyTorch,Yolo,Zero-shot</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov8x-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8x-coco-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv8x model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,PyTorch,Yolo,Polylines,Obb>

<div class="card tutorials-card" link=models.html#yolov8x-obb-dotav1-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8x-obb-dotav1-torch</h4>
</div>

<p class="card-summary">YOLOv8x Oriented Bounding Box model</p>

<p class="tags">Detection,PyTorch,Yolo,Polylines,Obb</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Oiv7,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov8x-oiv7-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8x-oiv7-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv8x model trained Open Images v7</p>

<p class="tags">Detection,Oiv7,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov8x-seg-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8x-seg-coco-torch</h4>
</div>

<p class="card-summary">Ultralytics YOLOv8x Segmentation model trained on COCO</p>

<p class="tags">Segmentation,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,PyTorch,Yolo,Zero-shot>

<div class="card tutorials-card" link=models.html#yolov8x-world-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov8x-world-torch</h4>
</div>

<p class="card-summary">YOLOv8x-World model</p>

<p class="tags">Detection,PyTorch,Yolo,Zero-shot</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov9c-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov9c-coco-torch</h4>
</div>

<p class="card-summary">YOLOv9-C model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov9c-seg-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov9c-seg-coco-torch</h4>
</div>

<p class="card-summary">YOLOv9-C Segmentation model trained on COCO</p>

<p class="tags">Segmentation,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov9e-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov9e-coco-torch</h4>
</div>

<p class="card-summary">YOLOv9-E model trained on COCO</p>

<p class="tags">Detection,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Segmentation,Coco,PyTorch,Yolo>

<div class="card tutorials-card" link=models.html#yolov9e-seg-coco-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>yolov9e-seg-coco-torch</h4>
</div>

<p class="card-summary">YOLOv9-E Segmentation model trained on COCO</p>

<p class="tags">Segmentation,Coco,PyTorch,Yolo</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Classification,Logits,Embeddings,PyTorch,Transformers,Zero-shot>

<div class="card tutorials-card" link=models.html#zero-shot-classification-transformer-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>zero-shot-classification-transformer-torch</h4>
</div>

<p class="card-summary">Hugging Face Transformers model for zero-shot image classification</p>

<p class="tags">Classification,Logits,Embeddings,PyTorch,Transformers,Zero-shot</p>



</div>

</div>

</div></p>
<p><div class="col-md-12 tutorials-card-container" data-tags=Detection,Logits,Embeddings,PyTorch,Transformers,Zero-shot>

<div class="card tutorials-card" link=models.html#zero-shot-detection-transformer-torch>

<div class="card-body">

<div class="card-title-container">
    <h4>zero-shot-detection-transformer-torch</h4>
</div>

<p class="card-summary">Hugging Face Transformers model for zero-shot object detection</p>

<p class="tags">Detection,Logits,Embeddings,PyTorch,Transformers,Zero-shot</p>



</div>

</div>

</div></p>
</div>

<div class="pagination d-flex justify-content-center"></div>

</div>

</div><div class="section" id="torch-models">
<span id="model-zoo-torch-models"></span><h2>Torch models<a class="headerlink" href="#torch-models" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="alexnet-imagenet-torch">
<span id="model-zoo-alexnet-imagenet-torch"></span><h3>alexnet-imagenet-torch<a class="headerlink" href="#alexnet-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>AlexNet model architecture from <a class="reference external" href="https://arxiv.org/abs/1404.5997">One weird trick for parallelizing convolutional neural networks</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">alexnet-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 233.10 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">alexnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;alexnet-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="classification-transformer-torch">
<span id="model-zoo-classification-transformer-torch"></span><h3>classification-transformer-torch<a class="headerlink" href="#classification-transformer-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Hugging Face Transformers model for image classification.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">classification-transformer-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://huggingface.co/docs/transformers/tasks/image_classification">https://huggingface.co/docs/transformers/tasks/image_classification</a></p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">logits,</span> <span class="pre">embeddings,</span> <span class="pre">torch,</span> <span class="pre">transformers</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision,</span> <span class="pre">transformers</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;classification-transformer-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="clip-vit-base32-torch">
<span id="model-zoo-clip-vit-base32-torch"></span><h3>clip-vit-base32-torch<a class="headerlink" href="#clip-vit-base32-torch" title="Permalink to this headline">Â¶</a></h3>
<p>CLIP text/image encoder from <a class="reference external" href="https://arxiv.org/abs/2103.00020">Learning Transferable Visual Models From Natural Language Supervision</a> trained on 400M text-image pairs.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">clip-vit-base32-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/openai/CLIP">https://github.com/openai/CLIP</a></p></li>
<li><p>Model size: 337.58 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">logits,</span> <span class="pre">embeddings,</span> <span class="pre">torch,</span> <span class="pre">clip,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;clip-vit-base32-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

<span class="c1">#</span>
<span class="c1"># Make zero-shot predictions with custom classes</span>
<span class="c1">#</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span>
    <span class="s2">&quot;clip-vit-base32-torch&quot;</span><span class="p">,</span>
    <span class="n">text_prompt</span><span class="o">=</span><span class="s2">&quot;A photo of a&quot;</span><span class="p">,</span>
    <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;person&quot;</span><span class="p">,</span> <span class="s2">&quot;dog&quot;</span><span class="p">,</span> <span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;bird&quot;</span><span class="p">,</span> <span class="s2">&quot;car&quot;</span><span class="p">,</span> <span class="s2">&quot;tree&quot;</span><span class="p">,</span> <span class="s2">&quot;chair&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>
<span class="n">session</span><span class="o">.</span><span class="n">refresh</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="deeplabv3-resnet101-coco-torch">
<span id="model-zoo-deeplabv3-resnet101-coco-torch"></span><h3>deeplabv3-resnet101-coco-torch<a class="headerlink" href="#deeplabv3-resnet101-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>DeepLabV3 model from <a class="reference external" href="https://arxiv.org/abs/1706.05587">Rethinking Atrous Convolution for Semantic Image Segmentation</a> with ResNet-101 backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">deeplabv3-resnet101-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 233.22 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">resnet,</span> <span class="pre">deeplabv3</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;deeplabv3-resnet101-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="deeplabv3-resnet50-coco-torch">
<span id="model-zoo-deeplabv3-resnet50-coco-torch"></span><h3>deeplabv3-resnet50-coco-torch<a class="headerlink" href="#deeplabv3-resnet50-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>DeepLabV3 model from <a class="reference external" href="https://arxiv.org/abs/1706.05587">Rethinking Atrous Convolution for Semantic Image Segmentation</a> with ResNet-50 backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">deeplabv3-resnet50-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 160.51 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">resnet,</span> <span class="pre">deeplabv3</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;deeplabv3-resnet50-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="densenet121-imagenet-torch">
<span id="model-zoo-densenet121-imagenet-torch"></span><h3>densenet121-imagenet-torch<a class="headerlink" href="#densenet121-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Densenet-121 model from <a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">Densely Connected Convolutional Networks</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">densenet121-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 30.84 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">densenet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;densenet121-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="densenet161-imagenet-torch">
<span id="model-zoo-densenet161-imagenet-torch"></span><h3>densenet161-imagenet-torch<a class="headerlink" href="#densenet161-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Densenet-161 model from <a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">Densely Connected Convolutional Networks</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">densenet161-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 110.37 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">densenet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;densenet161-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="densenet169-imagenet-torch">
<span id="model-zoo-densenet169-imagenet-torch"></span><h3>densenet169-imagenet-torch<a class="headerlink" href="#densenet169-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Densenet-169 model from <a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">Densely Connected Convolutional Networks</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">densenet169-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 54.71 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">densenet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;densenet169-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="densenet201-imagenet-torch">
<span id="model-zoo-densenet201-imagenet-torch"></span><h3>densenet201-imagenet-torch<a class="headerlink" href="#densenet201-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Densenet-201 model from <a class="reference external" href="https://arxiv.org/pdf/1608.06993.pdf">Densely Connected Convolutional Networks</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">densenet201-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 77.37 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">densenet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;densenet201-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="depth-estimation-transformer-torch">
<span id="model-zoo-depth-estimation-transformer-torch"></span><h3>depth-estimation-transformer-torch<a class="headerlink" href="#depth-estimation-transformer-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Hugging Face Transformers model for monocular depth estimation.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">depth-estimation-transformer-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://huggingface.co/docs/transformers/tasks/monocular_depth_estimation">https://huggingface.co/docs/transformers/tasks/monocular_depth_estimation</a></p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">depth,</span> <span class="pre">torch,</span> <span class="pre">transformers</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision,</span> <span class="pre">transformers</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;depth-estimation-transformer-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="detection-transformer-torch">
<span id="model-zoo-detection-transformer-torch"></span><h3>detection-transformer-torch<a class="headerlink" href="#detection-transformer-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Hugging Face Transformers model for object detection.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">detection-transformer-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://huggingface.co/docs/transformers/tasks/object_detection">https://huggingface.co/docs/transformers/tasks/object_detection</a></p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">logits,</span> <span class="pre">embeddings,</span> <span class="pre">torch,</span> <span class="pre">transformers</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision,</span> <span class="pre">transformers</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;detection-transformer-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="dinov2-vitb14-reg-torch">
<span id="model-zoo-dinov2-vitb14-reg-torch"></span><h3>dinov2-vitb14-reg-torch<a class="headerlink" href="#dinov2-vitb14-reg-torch" title="Permalink to this headline">Â¶</a></h3>
<p>DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-B/14 distilled.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">dinov2-vitb14-reg-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/facebookresearch/dinov2">https://github.com/facebookresearch/dinov2</a></p></li>
<li><p>Model size: 330.35 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">embeddings,</span> <span class="pre">torch,</span> <span class="pre">dinov2</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;dinov2-vitb14-reg-torch&quot;</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="dinov2-vitb14-torch">
<span id="model-zoo-dinov2-vitb14-torch"></span><h3>dinov2-vitb14-torch<a class="headerlink" href="#dinov2-vitb14-torch" title="Permalink to this headline">Â¶</a></h3>
<p>DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-B/14 distilled.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">dinov2-vitb14-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/facebookresearch/dinov2">https://github.com/facebookresearch/dinov2</a></p></li>
<li><p>Model size: 330.33 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">embeddings,</span> <span class="pre">torch,</span> <span class="pre">dinov2</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;dinov2-vitb14-torch&quot;</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="dinov2-vitg14-reg-torch">
<span id="model-zoo-dinov2-vitg14-reg-torch"></span><h3>dinov2-vitg14-reg-torch<a class="headerlink" href="#dinov2-vitg14-reg-torch" title="Permalink to this headline">Â¶</a></h3>
<p>DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-g/14.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">dinov2-vitg14-reg-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/facebookresearch/dinov2">https://github.com/facebookresearch/dinov2</a></p></li>
<li><p>Model size: 4.23 GB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">embeddings,</span> <span class="pre">torch,</span> <span class="pre">dinov2</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;dinov2-vitg14-reg-torch&quot;</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="dinov2-vitg14-torch">
<span id="model-zoo-dinov2-vitg14-torch"></span><h3>dinov2-vitg14-torch<a class="headerlink" href="#dinov2-vitg14-torch" title="Permalink to this headline">Â¶</a></h3>
<p>DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-g/14.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">dinov2-vitg14-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/facebookresearch/dinov2">https://github.com/facebookresearch/dinov2</a></p></li>
<li><p>Model size: 4.23 GB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">embeddings,</span> <span class="pre">torch,</span> <span class="pre">dinov2</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;dinov2-vitg14-torch&quot;</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="dinov2-vitl14-reg-torch">
<span id="model-zoo-dinov2-vitl14-reg-torch"></span><h3>dinov2-vitl14-reg-torch<a class="headerlink" href="#dinov2-vitl14-reg-torch" title="Permalink to this headline">Â¶</a></h3>
<p>DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-L/14 distilled.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">dinov2-vitl14-reg-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/facebookresearch/dinov2">https://github.com/facebookresearch/dinov2</a></p></li>
<li><p>Model size: 1.13 GB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">embeddings,</span> <span class="pre">torch,</span> <span class="pre">dinov2</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;dinov2-vitl14-reg-torch&quot;</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="dinov2-vitl14-torch">
<span id="model-zoo-dinov2-vitl14-torch"></span><h3>dinov2-vitl14-torch<a class="headerlink" href="#dinov2-vitl14-torch" title="Permalink to this headline">Â¶</a></h3>
<p>DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-L/14 distilled.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">dinov2-vitl14-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/facebookresearch/dinov2">https://github.com/facebookresearch/dinov2</a></p></li>
<li><p>Model size: 1.13 GB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">embeddings,</span> <span class="pre">torch,</span> <span class="pre">dinov2</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;dinov2-vitl14-torch&quot;</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="dinov2-vits14-reg-torch">
<span id="model-zoo-dinov2-vits14-reg-torch"></span><h3>dinov2-vits14-reg-torch<a class="headerlink" href="#dinov2-vits14-reg-torch" title="Permalink to this headline">Â¶</a></h3>
<p>DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-S/14 distilled.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">dinov2-vits14-reg-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/facebookresearch/dinov2">https://github.com/facebookresearch/dinov2</a></p></li>
<li><p>Model size: 84.20 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">embeddings,</span> <span class="pre">torch,</span> <span class="pre">dinov2</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;dinov2-vits14-reg-torch&quot;</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="dinov2-vits14-torch">
<span id="model-zoo-dinov2-vits14-torch"></span><h3>dinov2-vits14-torch<a class="headerlink" href="#dinov2-vits14-torch" title="Permalink to this headline">Â¶</a></h3>
<p>DINOv2: Learning Robust Visual Features without Supervision. Model: ViT-S/14 distilled.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">dinov2-vits14-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/facebookresearch/dinov2">https://github.com/facebookresearch/dinov2</a></p></li>
<li><p>Model size: 84.19 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">embeddings,</span> <span class="pre">torch,</span> <span class="pre">dinov2</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;dinov2-vits14-torch&quot;</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">compute_embeddings</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="faster-rcnn-resnet50-fpn-coco-torch">
<span id="model-zoo-faster-rcnn-resnet50-fpn-coco-torch"></span><h3>faster-rcnn-resnet50-fpn-coco-torch<a class="headerlink" href="#faster-rcnn-resnet50-fpn-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Faster R-CNN model from <a class="reference external" href="https://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a> with ResNet-50 FPN backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">faster-rcnn-resnet50-fpn-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 159.74 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">faster-rcnn,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;faster-rcnn-resnet50-fpn-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="fcn-resnet101-coco-torch">
<span id="model-zoo-fcn-resnet101-coco-torch"></span><h3>fcn-resnet101-coco-torch<a class="headerlink" href="#fcn-resnet101-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>FCN model from <a class="reference external" href="https://arxiv.org/abs/1411.4038">Fully Convolutional Networks for Semantic Segmentation</a> with ResNet-101 backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">fcn-resnet101-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 207.71 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">fcn,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;fcn-resnet101-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="fcn-resnet50-coco-torch">
<span id="model-zoo-fcn-resnet50-coco-torch"></span><h3>fcn-resnet50-coco-torch<a class="headerlink" href="#fcn-resnet50-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>FCN model from <a class="reference external" href="https://arxiv.org/abs/1411.4038">Fully Convolutional Networks for Semantic Segmentation</a> with ResNet-50 backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">fcn-resnet50-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 135.01 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">fcn,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;fcn-resnet50-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="googlenet-imagenet-torch">
<span id="model-zoo-googlenet-imagenet-torch"></span><h3>googlenet-imagenet-torch<a class="headerlink" href="#googlenet-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>GoogLeNet (Inception v1) model from <a class="reference external" href="https://arxiv.org/abs/1409.4842">Going Deeper with Convolutions</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">googlenet-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 49.73 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">googlenet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">scipy,</span> <span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;googlenet-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="inception-v3-imagenet-torch">
<span id="model-zoo-inception-v3-imagenet-torch"></span><h3>inception-v3-imagenet-torch<a class="headerlink" href="#inception-v3-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Inception v3 model from <a class="reference external" href="https://arxiv.org/abs/1512.00567">Rethinking the Inception Architecture for Computer Vision</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">inception-v3-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 103.81 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">inception</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">scipy,</span> <span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;inception-v3-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="keypoint-rcnn-resnet50-fpn-coco-torch">
<span id="model-zoo-keypoint-rcnn-resnet50-fpn-coco-torch"></span><h3>keypoint-rcnn-resnet50-fpn-coco-torch<a class="headerlink" href="#keypoint-rcnn-resnet50-fpn-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Keypoint R-CNN model from <a class="reference external" href="https://arxiv.org/abs/1703.06870">Mask R-CNN</a> with ResNet-50 FPN backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">keypoint-rcnn-resnet50-fpn-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 226.05 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">keypoints,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">keypoint-rcnn,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;keypoint-rcnn-resnet50-fpn-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="mask-rcnn-resnet50-fpn-coco-torch">
<span id="model-zoo-mask-rcnn-resnet50-fpn-coco-torch"></span><h3>mask-rcnn-resnet50-fpn-coco-torch<a class="headerlink" href="#mask-rcnn-resnet50-fpn-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Mask R-CNN model from <a class="reference external" href="https://arxiv.org/abs/1703.06870">Mask R-CNN</a> with ResNet-50 FPN backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">mask-rcnn-resnet50-fpn-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 169.84 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">instances,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">mask-rcnn,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;mask-rcnn-resnet50-fpn-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="med-sam-2-video-torch">
<span id="model-zoo-med-sam-2-video-torch"></span><h3>med-sam-2-video-torch<a class="headerlink" href="#med-sam-2-video-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Fine-tuned SAM2-hiera-tiny model from <a class="reference external" href="https://arxiv.org/abs/2408.00874">Medical SAM 2 - Segment Medical Images as Video via Segment Anything Model 2</a>.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">med-sam-2-video-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/MedicineToken/Medical-SAM2">https://github.com/MedicineToken/Medical-SAM2</a></p></li>
<li><p>Model size: 148.68 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">torch,</span> <span class="pre">zero-shot,</span> <span class="pre">video,</span> <span class="pre">med-SAM</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>
<span class="kn">from</span> <span class="nn">fiftyone</span> <span class="kn">import</span> <span class="n">ViewField</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">fiftyone.utils.huggingface</span> <span class="kn">import</span> <span class="n">load_from_hub</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_from_hub</span><span class="p">(</span><span class="s2">&quot;Voxel51/BTCV-CT-as-video-MedSAM2-dataset&quot;</span><span class="p">)[:</span><span class="mi">2</span><span class="p">]</span>

<span class="c1"># Retaining detections from a single frame in the middle</span>
<span class="c1"># Note that SAM2 only propagates segmentation masks forward in a video</span>
<span class="p">(</span>
    <span class="n">dataset</span>
    <span class="o">.</span><span class="n">match_frames</span><span class="p">(</span><span class="n">F</span><span class="p">(</span><span class="s2">&quot;frame_number&quot;</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">100</span><span class="p">)</span>
    <span class="o">.</span><span class="n">set_field</span><span class="p">(</span><span class="s2">&quot;frames.gt_detections&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="o">.</span><span class="n">save</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;med-sam-2-video-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes and propagate to all frames</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;pred_segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;frames.gt_detections&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="mnasnet0-5-imagenet-torch">
<span id="model-zoo-mnasnet0-5-imagenet-torch"></span><h3>mnasnet0.5-imagenet-torch<a class="headerlink" href="#mnasnet0-5-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>MNASNet model from from <a class="reference external" href="https://arxiv.org/abs/1807.11626">MnasNet: Platform-Aware Neural Architecture Search for Mobile</a> with depth multiplier of 0.5 trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">mnasnet0.5-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 8.59 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">mnasnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;mnasnet0.5-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="mnasnet1-0-imagenet-torch">
<span id="model-zoo-mnasnet1-0-imagenet-torch"></span><h3>mnasnet1.0-imagenet-torch<a class="headerlink" href="#mnasnet1-0-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>MNASNet model from <a class="reference external" href="https://arxiv.org/abs/1807.11626">MnasNet: Platform-Aware Neural Architecture Search for Mobile</a> with depth multiplier of 1.0 trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">mnasnet1.0-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 16.92 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">mnasnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;mnasnet1.0-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="mobilenet-v2-imagenet-torch">
<span id="model-zoo-mobilenet-v2-imagenet-torch"></span><h3>mobilenet-v2-imagenet-torch<a class="headerlink" href="#mobilenet-v2-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>MobileNetV2 model from <a class="reference external" href="https://arxiv.org/abs/1801.04381">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">mobilenet-v2-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 13.55 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">mobilenet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;mobilenet-v2-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="open-clip-torch">
<span id="model-zoo-open-clip-torch"></span><h3>open-clip-torch<a class="headerlink" href="#open-clip-torch" title="Permalink to this headline">Â¶</a></h3>
<p>OPEN CLIP text/image encoder from <a class="reference external" href="https://arxiv.org/abs/2103.00020">Learning Transferable Visual Models From Natural Language Supervision</a> trained on 400M text-image pairs.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">open-clip-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/mlfoundations/open_clip">https://github.com/mlfoundations/open_clip</a></p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">logits,</span> <span class="pre">embeddings,</span> <span class="pre">torch,</span> <span class="pre">clip,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision,</span> <span class="pre">open_clip_torch</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;open-clip-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

<span class="c1">#</span>
<span class="c1"># Make zero-shot predictions with custom classes</span>
<span class="c1">#</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span>
    <span class="s2">&quot;open-clip-torch&quot;</span><span class="p">,</span>
    <span class="n">text_prompt</span><span class="o">=</span><span class="s2">&quot;A photo of a&quot;</span><span class="p">,</span>
    <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;person&quot;</span><span class="p">,</span> <span class="s2">&quot;dog&quot;</span><span class="p">,</span> <span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;bird&quot;</span><span class="p">,</span> <span class="s2">&quot;car&quot;</span><span class="p">,</span> <span class="s2">&quot;tree&quot;</span><span class="p">,</span> <span class="s2">&quot;chair&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>
<span class="n">session</span><span class="o">.</span><span class="n">refresh</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="resnet101-imagenet-torch">
<span id="model-zoo-resnet101-imagenet-torch"></span><h3>resnet101-imagenet-torch<a class="headerlink" href="#resnet101-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>ResNet-101 model from <a class="reference external" href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">resnet101-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 170.45 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;resnet101-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="resnet152-imagenet-torch">
<span id="model-zoo-resnet152-imagenet-torch"></span><h3>resnet152-imagenet-torch<a class="headerlink" href="#resnet152-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>ResNet-152 model from <a class="reference external" href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">resnet152-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 230.34 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;resnet152-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="resnet18-imagenet-torch">
<span id="model-zoo-resnet18-imagenet-torch"></span><h3>resnet18-imagenet-torch<a class="headerlink" href="#resnet18-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>ResNet-18 model from <a class="reference external" href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">resnet18-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 44.66 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;resnet18-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="resnet34-imagenet-torch">
<span id="model-zoo-resnet34-imagenet-torch"></span><h3>resnet34-imagenet-torch<a class="headerlink" href="#resnet34-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>ResNet-34 model from <a class="reference external" href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">resnet34-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 83.26 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;resnet34-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="resnet50-imagenet-torch">
<span id="model-zoo-resnet50-imagenet-torch"></span><h3>resnet50-imagenet-torch<a class="headerlink" href="#resnet50-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>ResNet-50 model from <a class="reference external" href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">resnet50-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 97.75 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;resnet50-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="resnext101-32x8d-imagenet-torch">
<span id="model-zoo-resnext101-32x8d-imagenet-torch"></span><h3>resnext101-32x8d-imagenet-torch<a class="headerlink" href="#resnext101-32x8d-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>ResNeXt-101 32x8d model from <a class="reference external" href="https://arxiv.org/abs/1611.05431">Aggregated Residual Transformations for Deep Neural Networks</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">resnext101-32x8d-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 339.59 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">resnext</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;resnext101-32x8d-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="resnext50-32x4d-imagenet-torch">
<span id="model-zoo-resnext50-32x4d-imagenet-torch"></span><h3>resnext50-32x4d-imagenet-torch<a class="headerlink" href="#resnext50-32x4d-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>ResNeXt-50 32x4d model from <a class="reference external" href="https://arxiv.org/abs/1611.05431">Aggregated Residual Transformations for Deep Neural Networks</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">resnext50-32x4d-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 95.79 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">resnext</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;resnext50-32x4d-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="retinanet-resnet50-fpn-coco-torch">
<span id="model-zoo-retinanet-resnet50-fpn-coco-torch"></span><h3>retinanet-resnet50-fpn-coco-torch<a class="headerlink" href="#retinanet-resnet50-fpn-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>RetinaNet model from <a class="reference external" href="https://arxiv.org/abs/1708.02002">Focal Loss for Dense Object Detection</a> with ResNet-50 FPN backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">retinanet-resnet50-fpn-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 130.27 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">retinanet,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision&gt;=0.8.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;retinanet-resnet50-fpn-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="rtdetr-l-coco-torch">
<span id="model-zoo-rtdetr-l-coco-torch"></span><h3>rtdetr-l-coco-torch<a class="headerlink" href="#rtdetr-l-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>RT-DETR-l model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">rtdetr-l-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/rtdetr/">https://docs.ultralytics.com/models/rtdetr/</a></p></li>
<li><p>Model size: 63.43 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">transformer,</span> <span class="pre">rtdetr</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.2.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;rtdetr-l-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="rtdetr-x-coco-torch">
<span id="model-zoo-rtdetr-x-coco-torch"></span><h3>rtdetr-x-coco-torch<a class="headerlink" href="#rtdetr-x-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>RT-DETR-x model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">rtdetr-x-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/rtdetr/">https://docs.ultralytics.com/models/rtdetr/</a></p></li>
<li><p>Model size: 129.47 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">transformer,</span> <span class="pre">rtdetr</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.2.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;rtdetr-x-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-2-hiera-base-plus-image-torch">
<span id="model-zoo-segment-anything-2-hiera-base-plus-image-torch"></span><h3>segment-anything-2-hiera-base-plus-image-torch<a class="headerlink" href="#segment-anything-2-hiera-base-plus-image-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model 2 (SAM2) from <a class="reference external" href="https://arxiv.org/abs/2408.00714">SAM2: Segment Anything in Images and Videos</a>.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-2-hiera-base-plus-image-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://ai.meta.com/sam2/">https://ai.meta.com/sam2/</a></p></li>
<li><p>Model size: 148.68 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">torch,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-2-hiera-base-plus-image-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;ground_truth&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="c1"># Full automatic segmentations</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-2-hiera-base-plus-video-torch">
<span id="model-zoo-segment-anything-2-hiera-base-plus-video-torch"></span><h3>segment-anything-2-hiera-base-plus-video-torch<a class="headerlink" href="#segment-anything-2-hiera-base-plus-video-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model 2 (SAM2) from <a class="reference external" href="https://arxiv.org/abs/2408.00714">SAM2: Segment Anything in Images and Videos</a>.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-2-hiera-base-plus-video-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://ai.meta.com/sam2/">https://ai.meta.com/sam2/</a></p></li>
<li><p>Model size: 148.68 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">torch,</span> <span class="pre">zero-shot,</span> <span class="pre">video</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>
<span class="kn">from</span> <span class="nn">fiftyone</span> <span class="kn">import</span> <span class="n">ViewField</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span><span class="s2">&quot;quickstart-video&quot;</span><span class="p">,</span> <span class="n">max_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Only retain detections in the first frame</span>
<span class="p">(</span>
    <span class="n">dataset</span>
    <span class="o">.</span><span class="n">match_frames</span><span class="p">(</span><span class="n">F</span><span class="p">(</span><span class="s2">&quot;frame_number&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
    <span class="o">.</span><span class="n">set_field</span><span class="p">(</span><span class="s2">&quot;frames.detections&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="o">.</span><span class="n">save</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-2-hiera-base-plus-video-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes and propagate to all frames</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;frames.detections&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-2-hiera-large-image-torch">
<span id="model-zoo-segment-anything-2-hiera-large-image-torch"></span><h3>segment-anything-2-hiera-large-image-torch<a class="headerlink" href="#segment-anything-2-hiera-large-image-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model 2 (SAM2) from <a class="reference external" href="https://arxiv.org/abs/2408.00714">SAM2: Segment Anything in Images and Videos</a>.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-2-hiera-large-image-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://ai.meta.com/sam2/">https://ai.meta.com/sam2/</a></p></li>
<li><p>Model size: 148.68 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">torch,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-2-hiera-large-image-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;ground_truth&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="c1"># Full automatic segmentations</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-2-hiera-large-video-torch">
<span id="model-zoo-segment-anything-2-hiera-large-video-torch"></span><h3>segment-anything-2-hiera-large-video-torch<a class="headerlink" href="#segment-anything-2-hiera-large-video-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model 2 (SAM2) from <a class="reference external" href="https://arxiv.org/abs/2408.00714">SAM2: Segment Anything in Images and Videos</a>.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-2-hiera-large-video-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://ai.meta.com/sam2/">https://ai.meta.com/sam2/</a></p></li>
<li><p>Model size: 148.68 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">torch,</span> <span class="pre">zero-shot,</span> <span class="pre">video</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>
<span class="kn">from</span> <span class="nn">fiftyone</span> <span class="kn">import</span> <span class="n">ViewField</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span><span class="s2">&quot;quickstart-video&quot;</span><span class="p">,</span> <span class="n">max_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Only retain detections in the first frame</span>
<span class="p">(</span>
    <span class="n">dataset</span>
    <span class="o">.</span><span class="n">match_frames</span><span class="p">(</span><span class="n">F</span><span class="p">(</span><span class="s2">&quot;frame_number&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
    <span class="o">.</span><span class="n">set_field</span><span class="p">(</span><span class="s2">&quot;frames.detections&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="o">.</span><span class="n">save</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-2-hiera-large-video-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes and propagate to all frames</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;frames.detections&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-2-hiera-small-image-torch">
<span id="model-zoo-segment-anything-2-hiera-small-image-torch"></span><h3>segment-anything-2-hiera-small-image-torch<a class="headerlink" href="#segment-anything-2-hiera-small-image-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model 2 (SAM2) from <a class="reference external" href="https://arxiv.org/abs/2408.00714">SAM2: Segment Anything in Images and Videos</a>.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-2-hiera-small-image-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://ai.meta.com/sam2/">https://ai.meta.com/sam2/</a></p></li>
<li><p>Model size: 148.68 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">torch,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-2-hiera-small-image-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;ground_truth&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="c1"># Full automatic segmentations</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-2-hiera-small-video-torch">
<span id="model-zoo-segment-anything-2-hiera-small-video-torch"></span><h3>segment-anything-2-hiera-small-video-torch<a class="headerlink" href="#segment-anything-2-hiera-small-video-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model 2 (SAM2) from <a class="reference external" href="https://arxiv.org/abs/2408.00714">SAM2: Segment Anything in Images and Videos</a>.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-2-hiera-small-video-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://ai.meta.com/sam2/">https://ai.meta.com/sam2/</a></p></li>
<li><p>Model size: 148.68 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">torch,</span> <span class="pre">zero-shot,</span> <span class="pre">video</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>
<span class="kn">from</span> <span class="nn">fiftyone</span> <span class="kn">import</span> <span class="n">ViewField</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span><span class="s2">&quot;quickstart-video&quot;</span><span class="p">,</span> <span class="n">max_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Only retain detections in the first frame</span>
<span class="p">(</span>
    <span class="n">dataset</span>
    <span class="o">.</span><span class="n">match_frames</span><span class="p">(</span><span class="n">F</span><span class="p">(</span><span class="s2">&quot;frame_number&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
    <span class="o">.</span><span class="n">set_field</span><span class="p">(</span><span class="s2">&quot;frames.detections&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="o">.</span><span class="n">save</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-2-hiera-small-video-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes and propagate to all frames</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;frames.detections&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-2-hiera-tiny-image-torch">
<span id="model-zoo-segment-anything-2-hiera-tiny-image-torch"></span><h3>segment-anything-2-hiera-tiny-image-torch<a class="headerlink" href="#segment-anything-2-hiera-tiny-image-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model 2 (SAM2) from <a class="reference external" href="https://arxiv.org/abs/2408.00714">SAM2: Segment Anything in Images and Videos</a>.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-2-hiera-tiny-image-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://ai.meta.com/sam2/">https://ai.meta.com/sam2/</a></p></li>
<li><p>Model size: 148.68 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">torch,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-2-hiera-tiny-image-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;ground_truth&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="c1"># Full automatic segmentations</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-2-hiera-tiny-video-torch">
<span id="model-zoo-segment-anything-2-hiera-tiny-video-torch"></span><h3>segment-anything-2-hiera-tiny-video-torch<a class="headerlink" href="#segment-anything-2-hiera-tiny-video-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model 2 (SAM2) from <a class="reference external" href="https://arxiv.org/abs/2408.00714">SAM2: Segment Anything in Images and Videos</a>.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-2-hiera-tiny-video-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://ai.meta.com/sam2/">https://ai.meta.com/sam2/</a></p></li>
<li><p>Model size: 148.68 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">torch,</span> <span class="pre">zero-shot,</span> <span class="pre">video</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>
<span class="kn">from</span> <span class="nn">fiftyone</span> <span class="kn">import</span> <span class="n">ViewField</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span><span class="s2">&quot;quickstart-video&quot;</span><span class="p">,</span> <span class="n">max_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Only retain detections in the first frame</span>
<span class="p">(</span>
    <span class="n">dataset</span>
    <span class="o">.</span><span class="n">match_frames</span><span class="p">(</span><span class="n">F</span><span class="p">(</span><span class="s2">&quot;frame_number&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
    <span class="o">.</span><span class="n">set_field</span><span class="p">(</span><span class="s2">&quot;frames.detections&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="o">.</span><span class="n">save</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-2-hiera-tiny-video-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes and propagate to all frames</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;frames.detections&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-2-1-hiera-base-plus-image-torch">
<span id="model-zoo-segment-anything-2-1-hiera-base-plus-image-torch"></span><h3>segment-anything-2.1-hiera-base-plus-image-torch<a class="headerlink" href="#segment-anything-2-1-hiera-base-plus-image-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model 2 (SAM2) from <a class="reference external" href="https://arxiv.org/abs/2408.00714">SAM2: Segment Anything in Images and Videos</a>.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-2.1-hiera-base-plus-image-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://ai.meta.com/sam2/">https://ai.meta.com/sam2/</a></p></li>
<li><p>Model size: 148.68 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">torch,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-2.1-hiera-base-plus-image-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;ground_truth&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="c1"># Full automatic segmentations</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-2-1-hiera-base-plus-video-torch">
<span id="model-zoo-segment-anything-2-1-hiera-base-plus-video-torch"></span><h3>segment-anything-2.1-hiera-base-plus-video-torch<a class="headerlink" href="#segment-anything-2-1-hiera-base-plus-video-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model 2 (SAM2) from <a class="reference external" href="https://arxiv.org/abs/2408.00714">SAM2: Segment Anything in Images and Videos</a>.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-2.1-hiera-base-plus-video-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://ai.meta.com/sam2/">https://ai.meta.com/sam2/</a></p></li>
<li><p>Model size: 148.68 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">torch,</span> <span class="pre">zero-shot,</span> <span class="pre">video</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>
<span class="kn">from</span> <span class="nn">fiftyone</span> <span class="kn">import</span> <span class="n">ViewField</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span><span class="s2">&quot;quickstart-video&quot;</span><span class="p">,</span> <span class="n">max_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Only retain detections in the first frame</span>
<span class="p">(</span>
    <span class="n">dataset</span>
    <span class="o">.</span><span class="n">match_frames</span><span class="p">(</span><span class="n">F</span><span class="p">(</span><span class="s2">&quot;frame_number&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
    <span class="o">.</span><span class="n">set_field</span><span class="p">(</span><span class="s2">&quot;frames.detections&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="o">.</span><span class="n">save</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-2.1-hiera-base-plus-video-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes and propagate to all frames</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;frames.detections&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-2-1-hiera-large-image-torch">
<span id="model-zoo-segment-anything-2-1-hiera-large-image-torch"></span><h3>segment-anything-2.1-hiera-large-image-torch<a class="headerlink" href="#segment-anything-2-1-hiera-large-image-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model 2 (SAM2) from <a class="reference external" href="https://arxiv.org/abs/2408.00714">SAM2: Segment Anything in Images and Videos</a>.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-2.1-hiera-large-image-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://ai.meta.com/sam2/">https://ai.meta.com/sam2/</a></p></li>
<li><p>Model size: 148.68 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">torch,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-2.1-hiera-large-image-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;ground_truth&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="c1"># Full automatic segmentations</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-2-1-hiera-large-video-torch">
<span id="model-zoo-segment-anything-2-1-hiera-large-video-torch"></span><h3>segment-anything-2.1-hiera-large-video-torch<a class="headerlink" href="#segment-anything-2-1-hiera-large-video-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model 2 (SAM2) from <a class="reference external" href="https://arxiv.org/abs/2408.00714">SAM2: Segment Anything in Images and Videos</a>.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-2.1-hiera-large-video-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://ai.meta.com/sam2/">https://ai.meta.com/sam2/</a></p></li>
<li><p>Model size: 148.68 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">torch,</span> <span class="pre">zero-shot,</span> <span class="pre">video</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>
<span class="kn">from</span> <span class="nn">fiftyone</span> <span class="kn">import</span> <span class="n">ViewField</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span><span class="s2">&quot;quickstart-video&quot;</span><span class="p">,</span> <span class="n">max_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Only retain detections in the first frame</span>
<span class="p">(</span>
    <span class="n">dataset</span>
    <span class="o">.</span><span class="n">match_frames</span><span class="p">(</span><span class="n">F</span><span class="p">(</span><span class="s2">&quot;frame_number&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
    <span class="o">.</span><span class="n">set_field</span><span class="p">(</span><span class="s2">&quot;frames.detections&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="o">.</span><span class="n">save</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-2.1-hiera-large-video-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes and propagate to all frames</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;frames.detections&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-2-1-hiera-small-image-torch">
<span id="model-zoo-segment-anything-2-1-hiera-small-image-torch"></span><h3>segment-anything-2.1-hiera-small-image-torch<a class="headerlink" href="#segment-anything-2-1-hiera-small-image-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model 2 (SAM2) from <a class="reference external" href="https://arxiv.org/abs/2408.00714">SAM2: Segment Anything in Images and Videos</a>.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-2.1-hiera-small-image-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://ai.meta.com/sam2/">https://ai.meta.com/sam2/</a></p></li>
<li><p>Model size: 148.68 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">torch,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-2.1-hiera-small-image-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;ground_truth&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="c1"># Full automatic segmentations</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-2-1-hiera-small-video-torch">
<span id="model-zoo-segment-anything-2-1-hiera-small-video-torch"></span><h3>segment-anything-2.1-hiera-small-video-torch<a class="headerlink" href="#segment-anything-2-1-hiera-small-video-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model 2 (SAM2) from <a class="reference external" href="https://arxiv.org/abs/2408.00714">SAM2: Segment Anything in Images and Videos</a>.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-2.1-hiera-small-video-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://ai.meta.com/sam2/">https://ai.meta.com/sam2/</a></p></li>
<li><p>Model size: 148.68 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">torch,</span> <span class="pre">zero-shot,</span> <span class="pre">video</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>
<span class="kn">from</span> <span class="nn">fiftyone</span> <span class="kn">import</span> <span class="n">ViewField</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span><span class="s2">&quot;quickstart-video&quot;</span><span class="p">,</span> <span class="n">max_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Only retain detections in the first frame</span>
<span class="p">(</span>
    <span class="n">dataset</span>
    <span class="o">.</span><span class="n">match_frames</span><span class="p">(</span><span class="n">F</span><span class="p">(</span><span class="s2">&quot;frame_number&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
    <span class="o">.</span><span class="n">set_field</span><span class="p">(</span><span class="s2">&quot;frames.detections&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="o">.</span><span class="n">save</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-2.1-hiera-small-video-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes and propagate to all frames</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;frames.detections&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-2-1-hiera-tiny-image-torch">
<span id="model-zoo-segment-anything-2-1-hiera-tiny-image-torch"></span><h3>segment-anything-2.1-hiera-tiny-image-torch<a class="headerlink" href="#segment-anything-2-1-hiera-tiny-image-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model 2 (SAM2) from <a class="reference external" href="https://arxiv.org/abs/2408.00714">SAM2: Segment Anything in Images and Videos</a>.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-2.1-hiera-tiny-image-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://ai.meta.com/sam2/">https://ai.meta.com/sam2/</a></p></li>
<li><p>Model size: 148.68 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">torch,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-2.1-hiera-tiny-image-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;ground_truth&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="c1"># Full automatic segmentations</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-2-1-hiera-tiny-video-torch">
<span id="model-zoo-segment-anything-2-1-hiera-tiny-video-torch"></span><h3>segment-anything-2.1-hiera-tiny-video-torch<a class="headerlink" href="#segment-anything-2-1-hiera-tiny-video-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model 2 (SAM2) from <a class="reference external" href="https://arxiv.org/abs/2408.00714">SAM2: Segment Anything in Images and Videos</a>.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-2.1-hiera-tiny-video-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://ai.meta.com/sam2/">https://ai.meta.com/sam2/</a></p></li>
<li><p>Model size: 148.68 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">torch,</span> <span class="pre">zero-shot,</span> <span class="pre">video</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>
<span class="kn">from</span> <span class="nn">fiftyone</span> <span class="kn">import</span> <span class="n">ViewField</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span><span class="s2">&quot;quickstart-video&quot;</span><span class="p">,</span> <span class="n">max_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Only retain detections in the first frame</span>
<span class="p">(</span>
    <span class="n">dataset</span>
    <span class="o">.</span><span class="n">match_frames</span><span class="p">(</span><span class="n">F</span><span class="p">(</span><span class="s2">&quot;frame_number&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
    <span class="o">.</span><span class="n">set_field</span><span class="p">(</span><span class="s2">&quot;frames.detections&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="o">.</span><span class="n">save</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-2.1-hiera-tiny-video-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes and propagate to all frames</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;frames.detections&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-vitb-torch">
<span id="model-zoo-segment-anything-vitb-torch"></span><h3>segment-anything-vitb-torch<a class="headerlink" href="#segment-anything-vitb-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model (SAM) from <a class="reference external" href="https://arxiv.org/abs/2304.02643">Segment Anything</a> with ViT-B/16 backbone trained on SA-1B.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-vitb-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://segment-anything.com">https://segment-anything.com</a></p></li>
<li><p>Model size: 715.34 KB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">sa-1b,</span> <span class="pre">torch,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision,</span> <span class="pre">segment-anything</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-vitb-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;ground_truth&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="c1"># Full automatic segmentations</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-vith-torch">
<span id="model-zoo-segment-anything-vith-torch"></span><h3>segment-anything-vith-torch<a class="headerlink" href="#segment-anything-vith-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model (SAM) from <a class="reference external" href="https://arxiv.org/abs/2304.02643">Segment Anything</a> with ViT-H/16 backbone trained on SA-1B.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-vith-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://segment-anything.com">https://segment-anything.com</a></p></li>
<li><p>Model size: 4.78 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">sa-1b,</span> <span class="pre">torch,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision,</span> <span class="pre">segment-anything</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-vith-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;ground_truth&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="c1"># Full automatic segmentations</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segment-anything-vitl-torch">
<span id="model-zoo-segment-anything-vitl-torch"></span><h3>segment-anything-vitl-torch<a class="headerlink" href="#segment-anything-vitl-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Segment Anything Model (SAM) from <a class="reference external" href="https://arxiv.org/abs/2304.02643">Segment Anything</a> with ViT-L/16 backbone trained on SA-1B.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segment-anything-vitl-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://segment-anything.com">https://segment-anything.com</a></p></li>
<li><p>Model size: 2.33 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segment-anything,</span> <span class="pre">sa-1b,</span> <span class="pre">torch,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision,</span> <span class="pre">segment-anything</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segment-anything-vitl-torch&quot;</span><span class="p">)</span>

<span class="c1"># Segment inside boxes</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;segmentations&quot;</span><span class="p">,</span>
    <span class="n">prompt_field</span><span class="o">=</span><span class="s2">&quot;ground_truth&quot;</span><span class="p">,</span>  <span class="c1"># can contain Detections or Keypoints</span>
<span class="p">)</span>

<span class="c1"># Full automatic segmentations</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segmentation-transformer-torch">
<span id="model-zoo-segmentation-transformer-torch"></span><h3>segmentation-transformer-torch<a class="headerlink" href="#segmentation-transformer-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Hugging Face Transformers model for semantic segmentation.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">segmentation-transformer-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://huggingface.co/docs/transformers/tasks/semantic_segmentation">https://huggingface.co/docs/transformers/tasks/semantic_segmentation</a></p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">torch,</span> <span class="pre">transformers</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision,</span> <span class="pre">transformers</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;segmentation-transformer-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="shufflenetv2-0-5x-imagenet-torch">
<span id="model-zoo-shufflenetv2-0-5x-imagenet-torch"></span><h3>shufflenetv2-0.5x-imagenet-torch<a class="headerlink" href="#shufflenetv2-0-5x-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>ShuffleNetV2 model from <a class="reference external" href="https://arxiv.org/abs/1807.11164">ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design</a> with 0.5x output channels trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">shufflenetv2-0.5x-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 5.28 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">shufflenet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;shufflenetv2-0.5x-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="shufflenetv2-1-0x-imagenet-torch">
<span id="model-zoo-shufflenetv2-1-0x-imagenet-torch"></span><h3>shufflenetv2-1.0x-imagenet-torch<a class="headerlink" href="#shufflenetv2-1-0x-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>ShuffleNetV2 model from <a class="reference external" href="https://arxiv.org/abs/1807.11164">ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design</a> with 1.0x output channels trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">shufflenetv2-1.0x-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 8.79 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">shufflenet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;shufflenetv2-1.0x-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="squeezenet-1-1-imagenet-torch">
<span id="model-zoo-squeezenet-1-1-imagenet-torch"></span><h3>squeezenet-1.1-imagenet-torch<a class="headerlink" href="#squeezenet-1-1-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>SqueezeNet 1.1 model from <a class="reference external" href="https://github.com/forresti/SqueezeNet/tree/master/SqueezeNet_v1.1">the official SqueezeNet repo</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">squeezenet-1.1-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 4.74 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">squeezenet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;squeezenet-1.1-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="squeezenet-imagenet-torch">
<span id="model-zoo-squeezenet-imagenet-torch"></span><h3>squeezenet-imagenet-torch<a class="headerlink" href="#squeezenet-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>SqueezeNet model from <a class="reference external" href="https://arxiv.org/abs/1602.07360">SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &lt;0.5MB model size</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">squeezenet-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 4.79 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">squeezenet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;squeezenet-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="vgg11-bn-imagenet-torch">
<span id="model-zoo-vgg11-bn-imagenet-torch"></span><h3>vgg11-bn-imagenet-torch<a class="headerlink" href="#vgg11-bn-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>VGG-11 model from <a class="reference external" href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a> with batch normalization trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">vgg11-bn-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 506.88 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">vgg</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;vgg11-bn-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="vgg11-imagenet-torch">
<span id="model-zoo-vgg11-imagenet-torch"></span><h3>vgg11-imagenet-torch<a class="headerlink" href="#vgg11-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>VGG-11 model from <a class="reference external" href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">vgg11-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 506.84 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">vgg</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;vgg11-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="vgg13-bn-imagenet-torch">
<span id="model-zoo-vgg13-bn-imagenet-torch"></span><h3>vgg13-bn-imagenet-torch<a class="headerlink" href="#vgg13-bn-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>VGG-13 model from <a class="reference external" href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a> with batch normalization trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">vgg13-bn-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 507.59 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">vgg</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;vgg13-bn-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="vgg13-imagenet-torch">
<span id="model-zoo-vgg13-imagenet-torch"></span><h3>vgg13-imagenet-torch<a class="headerlink" href="#vgg13-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>VGG-13 model from <a class="reference external" href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">vgg13-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 507.54 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">vgg</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;vgg13-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="vgg16-bn-imagenet-torch">
<span id="model-zoo-vgg16-bn-imagenet-torch"></span><h3>vgg16-bn-imagenet-torch<a class="headerlink" href="#vgg16-bn-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>VGG-16 model from <a class="reference external" href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a> with batch normalization trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">vgg16-bn-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 527.87 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">vgg</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;vgg16-bn-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="vgg16-imagenet-torch">
<span id="model-zoo-vgg16-imagenet-torch"></span><h3>vgg16-imagenet-torch<a class="headerlink" href="#vgg16-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>VGG-16 model from <a class="reference external" href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">vgg16-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 527.80 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">vgg</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;vgg16-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="vgg19-bn-imagenet-torch">
<span id="model-zoo-vgg19-bn-imagenet-torch"></span><h3>vgg19-bn-imagenet-torch<a class="headerlink" href="#vgg19-bn-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>VGG-19 model from <a class="reference external" href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a> with batch normalization trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">vgg19-bn-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 548.14 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">vgg</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;vgg19-bn-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="vgg19-imagenet-torch">
<span id="model-zoo-vgg19-imagenet-torch"></span><h3>vgg19-imagenet-torch<a class="headerlink" href="#vgg19-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>VGG-19 model from <a class="reference external" href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">vgg19-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 548.05 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">vgg</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;vgg19-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="wide-resnet101-2-imagenet-torch">
<span id="model-zoo-wide-resnet101-2-imagenet-torch"></span><h3>wide-resnet101-2-imagenet-torch<a class="headerlink" href="#wide-resnet101-2-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Wide ResNet-101-2 model from <a class="reference external" href="https://arxiv.org/abs/1605.07146">Wide Residual Networks</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">wide-resnet101-2-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 242.90 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">wide-resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;wide-resnet101-2-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="wide-resnet50-2-imagenet-torch">
<span id="model-zoo-wide-resnet50-2-imagenet-torch"></span><h3>wide-resnet50-2-imagenet-torch<a class="headerlink" href="#wide-resnet50-2-imagenet-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Wide ResNet-50-2 model from <a class="reference external" href="https://arxiv.org/abs/1605.07146">Wide Residual Networks</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">wide-resnet50-2-imagenet-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/main/models.html</a></p></li>
<li><p>Model size: 131.82 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">torch,</span> <span class="pre">wide-resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;wide-resnet50-2-imagenet-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolo-nas-torch">
<span id="model-zoo-yolo-nas-torch"></span><h3>yolo-nas-torch<a class="headerlink" href="#yolo-nas-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLO-NAS is an open-source training library for advanced computer vision models. It specializes in accuracy and efficiency, supporting tasks like object detection.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolo-nas-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/Deci-AI/super-gradients">https://github.com/Deci-AI/super-gradients</a></p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision,</span> <span class="pre">super-gradients</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolo-nas-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolo11l-coco-torch">
<span id="model-zoo-yolo11l-coco-torch"></span><h3>yolo11l-coco-torch<a class="headerlink" href="#yolo11l-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLO11-L model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolo11l-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov11/">https://docs.ultralytics.com/models/yolov11/</a></p></li>
<li><p>Model size: 49.01 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.3.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolo11l-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolo11l-seg-coco-torch">
<span id="model-zoo-yolo11l-seg-coco-torch"></span><h3>yolo11l-seg-coco-torch<a class="headerlink" href="#yolo11l-seg-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLO11-L Segmentation model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolo11l-seg-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolo11/#__tabbed_1_2">https://docs.ultralytics.com/models/yolo11/#__tabbed_1_2</a></p></li>
<li><p>Model size: 53.50 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.3.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolo11l-seg-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolo11m-coco-torch">
<span id="model-zoo-yolo11m-coco-torch"></span><h3>yolo11m-coco-torch<a class="headerlink" href="#yolo11m-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLO11-M model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolo11m-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov11/">https://docs.ultralytics.com/models/yolov11/</a></p></li>
<li><p>Model size: 38.80 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.3.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolo11m-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolo11m-seg-coco-torch">
<span id="model-zoo-yolo11m-seg-coco-torch"></span><h3>yolo11m-seg-coco-torch<a class="headerlink" href="#yolo11m-seg-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLO11-M Segmentation model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolo11m-seg-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolo11/#__tabbed_1_2">https://docs.ultralytics.com/models/yolo11/#__tabbed_1_2</a></p></li>
<li><p>Model size: 43.30 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.3.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolo11m-seg-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolo11n-coco-torch">
<span id="model-zoo-yolo11n-coco-torch"></span><h3>yolo11n-coco-torch<a class="headerlink" href="#yolo11n-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLO11-N model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolo11n-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov11/">https://docs.ultralytics.com/models/yolov11/</a></p></li>
<li><p>Model size: 5.35 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.3.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolo11n-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolo11n-seg-coco-torch">
<span id="model-zoo-yolo11n-seg-coco-torch"></span><h3>yolo11n-seg-coco-torch<a class="headerlink" href="#yolo11n-seg-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLO11-N Segmentation model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolo11n-seg-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolo11/#__tabbed_1_2">https://docs.ultralytics.com/models/yolo11/#__tabbed_1_2</a></p></li>
<li><p>Model size: 5.90 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.3.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolo11n-seg-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolo11s-coco-torch">
<span id="model-zoo-yolo11s-coco-torch"></span><h3>yolo11s-coco-torch<a class="headerlink" href="#yolo11s-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLO11-S model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolo11s-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov11/">https://docs.ultralytics.com/models/yolov11/</a></p></li>
<li><p>Model size: 18.42 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.3.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolo11s-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolo11s-seg-coco-torch">
<span id="model-zoo-yolo11s-seg-coco-torch"></span><h3>yolo11s-seg-coco-torch<a class="headerlink" href="#yolo11s-seg-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLO11-S Segmentation model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolo11s-seg-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolo11/#__tabbed_1_2">https://docs.ultralytics.com/models/yolo11/#__tabbed_1_2</a></p></li>
<li><p>Model size: 19.71 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.3.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolo11s-seg-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolo11x-coco-torch">
<span id="model-zoo-yolo11x-coco-torch"></span><h3>yolo11x-coco-torch<a class="headerlink" href="#yolo11x-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLO11-X model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolo11x-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov11/">https://docs.ultralytics.com/models/yolov11/</a></p></li>
<li><p>Model size: 109.33 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.3.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolo11x-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolo11x-seg-coco-torch">
<span id="model-zoo-yolo11x-seg-coco-torch"></span><h3>yolo11x-seg-coco-torch<a class="headerlink" href="#yolo11x-seg-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLO11-X Segmentation model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolo11x-seg-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolo11/#__tabbed_1_2">https://docs.ultralytics.com/models/yolo11/#__tabbed_1_2</a></p></li>
<li><p>Model size: 119.30 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.3.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolo11x-seg-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov10l-coco-torch">
<span id="model-zoo-yolov10l-coco-torch"></span><h3>yolov10l-coco-torch<a class="headerlink" href="#yolov10l-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv10-L model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov10l-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov10/">https://docs.ultralytics.com/models/yolov10/</a></p></li>
<li><p>Model size: 50.00 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.2.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov10l-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov10m-coco-torch">
<span id="model-zoo-yolov10m-coco-torch"></span><h3>yolov10m-coco-torch<a class="headerlink" href="#yolov10m-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv10-M model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov10m-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov10/">https://docs.ultralytics.com/models/yolov10/</a></p></li>
<li><p>Model size: 32.09 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.2.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov10m-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov10n-coco-torch">
<span id="model-zoo-yolov10n-coco-torch"></span><h3>yolov10n-coco-torch<a class="headerlink" href="#yolov10n-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv10-N model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov10n-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov10/">https://docs.ultralytics.com/models/yolov10/</a></p></li>
<li><p>Model size: 5.59 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.2.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov10n-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov10s-coco-torch">
<span id="model-zoo-yolov10s-coco-torch"></span><h3>yolov10s-coco-torch<a class="headerlink" href="#yolov10s-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv10-S model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov10s-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov10/">https://docs.ultralytics.com/models/yolov10/</a></p></li>
<li><p>Model size: 15.85 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.2.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov10s-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov10x-coco-torch">
<span id="model-zoo-yolov10x-coco-torch"></span><h3>yolov10x-coco-torch<a class="headerlink" href="#yolov10x-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv10-X model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov10x-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov10/">https://docs.ultralytics.com/models/yolov10/</a></p></li>
<li><p>Model size: 61.41 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.2.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov10x-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov5l-coco-torch">
<span id="model-zoo-yolov5l-coco-torch"></span><h3>yolov5l-coco-torch<a class="headerlink" href="#yolov5l-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv5l model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov5l-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/hub/ultralytics_yolov5">https://pytorch.org/hub/ultralytics_yolov5</a></p></li>
<li><p>Model size: 192.88 KB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov5l-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov5m-coco-torch">
<span id="model-zoo-yolov5m-coco-torch"></span><h3>yolov5m-coco-torch<a class="headerlink" href="#yolov5m-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv5m model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov5m-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/hub/ultralytics_yolov5">https://pytorch.org/hub/ultralytics_yolov5</a></p></li>
<li><p>Model size: 81.91 KB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov5m-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov5n-coco-torch">
<span id="model-zoo-yolov5n-coco-torch"></span><h3>yolov5n-coco-torch<a class="headerlink" href="#yolov5n-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv5n model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov5n-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/hub/ultralytics_yolov5">https://pytorch.org/hub/ultralytics_yolov5</a></p></li>
<li><p>Model size: 7.75 KB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov5n-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov5s-coco-torch">
<span id="model-zoo-yolov5s-coco-torch"></span><h3>yolov5s-coco-torch<a class="headerlink" href="#yolov5s-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv5s model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov5s-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/hub/ultralytics_yolov5">https://pytorch.org/hub/ultralytics_yolov5</a></p></li>
<li><p>Model size: 28.25 KB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov5s-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov5x-coco-torch">
<span id="model-zoo-yolov5x-coco-torch"></span><h3>yolov5x-coco-torch<a class="headerlink" href="#yolov5x-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv5x model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov5x-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://pytorch.org/hub/ultralytics_yolov5">https://pytorch.org/hub/ultralytics_yolov5</a></p></li>
<li><p>Model size: 352.05 KB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov5x-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8l-coco-torch">
<span id="model-zoo-yolov8l-coco-torch"></span><h3>yolov8l-coco-torch<a class="headerlink" href="#yolov8l-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv8l model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8l-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov8/">https://docs.ultralytics.com/models/yolov8/</a></p></li>
<li><p>Model size: 83.70 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8l-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8l-obb-dotav1-torch">
<span id="model-zoo-yolov8l-obb-dotav1-torch"></span><h3>yolov8l-obb-dotav1-torch<a class="headerlink" href="#yolov8l-obb-dotav1-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv8l Oriented Bounding Box model.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8l-obb-dotav1-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/tasks/obb/">https://docs.ultralytics.com/tasks/obb/</a></p></li>
<li><p>Model size: 85.36 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">torch,</span> <span class="pre">yolo,</span> <span class="pre">polylines,</span> <span class="pre">obb</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.1.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8l-obb-dotav1-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8l-oiv7-torch">
<span id="model-zoo-yolov8l-oiv7-torch"></span><h3>yolov8l-oiv7-torch<a class="headerlink" href="#yolov8l-oiv7-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv8l model trained Open Images v7.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8l-oiv7-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/datasets/detect/open-images-v7">https://docs.ultralytics.com/datasets/detect/open-images-v7</a></p></li>
<li><p>Model size: 83.70 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">oiv7,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8l-oiv7-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8l-seg-coco-torch">
<span id="model-zoo-yolov8l-seg-coco-torch"></span><h3>yolov8l-seg-coco-torch<a class="headerlink" href="#yolov8l-seg-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv8l Segmentation model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8l-seg-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov8/">https://docs.ultralytics.com/models/yolov8/</a></p></li>
<li><p>Model size: 88.11 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8l-seg-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8l-world-torch">
<span id="model-zoo-yolov8l-world-torch"></span><h3>yolov8l-world-torch<a class="headerlink" href="#yolov8l-world-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv8l-World model.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8l-world-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolo-world/">https://docs.ultralytics.com/models/yolo-world/</a></p></li>
<li><p>Model size: 91.23 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">torch,</span> <span class="pre">yolo,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.1.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8l-world-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8m-coco-torch">
<span id="model-zoo-yolov8m-coco-torch"></span><h3>yolov8m-coco-torch<a class="headerlink" href="#yolov8m-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv8m model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8m-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov8/">https://docs.ultralytics.com/models/yolov8/</a></p></li>
<li><p>Model size: 49.70 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8m-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8m-obb-dotav1-torch">
<span id="model-zoo-yolov8m-obb-dotav1-torch"></span><h3>yolov8m-obb-dotav1-torch<a class="headerlink" href="#yolov8m-obb-dotav1-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv8m Oriented Bounding Box model.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8m-obb-dotav1-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/tasks/obb/">https://docs.ultralytics.com/tasks/obb/</a></p></li>
<li><p>Model size: 50.84 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">torch,</span> <span class="pre">yolo,</span> <span class="pre">polylines,</span> <span class="pre">obb</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.1.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8m-obb-dotav1-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8m-oiv7-torch">
<span id="model-zoo-yolov8m-oiv7-torch"></span><h3>yolov8m-oiv7-torch<a class="headerlink" href="#yolov8m-oiv7-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv8m model trained Open Images v7.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8m-oiv7-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/datasets/detect/open-images-v7">https://docs.ultralytics.com/datasets/detect/open-images-v7</a></p></li>
<li><p>Model size: 49.70 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">oiv7,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8m-oiv7-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8m-seg-coco-torch">
<span id="model-zoo-yolov8m-seg-coco-torch"></span><h3>yolov8m-seg-coco-torch<a class="headerlink" href="#yolov8m-seg-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv8m Segmentation model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8m-seg-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov8/">https://docs.ultralytics.com/models/yolov8/</a></p></li>
<li><p>Model size: 52.36 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8m-seg-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8m-world-torch">
<span id="model-zoo-yolov8m-world-torch"></span><h3>yolov8m-world-torch<a class="headerlink" href="#yolov8m-world-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv8m-World model.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8m-world-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolo-world/">https://docs.ultralytics.com/models/yolo-world/</a></p></li>
<li><p>Model size: 55.89 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">torch,</span> <span class="pre">yolo,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.1.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8m-world-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8n-coco-torch">
<span id="model-zoo-yolov8n-coco-torch"></span><h3>yolov8n-coco-torch<a class="headerlink" href="#yolov8n-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv8n model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8n-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov8/">https://docs.ultralytics.com/models/yolov8/</a></p></li>
<li><p>Model size: 6.23 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8n-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8n-obb-dotav1-torch">
<span id="model-zoo-yolov8n-obb-dotav1-torch"></span><h3>yolov8n-obb-dotav1-torch<a class="headerlink" href="#yolov8n-obb-dotav1-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv8n Oriented Bounding Box model.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8n-obb-dotav1-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/tasks/obb/">https://docs.ultralytics.com/tasks/obb/</a></p></li>
<li><p>Model size: 6.24 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">torch,</span> <span class="pre">yolo,</span> <span class="pre">polylines,</span> <span class="pre">obb</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.1.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8n-obb-dotav1-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8n-oiv7-torch">
<span id="model-zoo-yolov8n-oiv7-torch"></span><h3>yolov8n-oiv7-torch<a class="headerlink" href="#yolov8n-oiv7-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv8n model trained on Open Images v7.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8n-oiv7-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/datasets/detect/open-images-v7">https://docs.ultralytics.com/datasets/detect/open-images-v7</a></p></li>
<li><p>Model size: 6.23 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">oiv7,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8n-oiv7-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8n-seg-coco-torch">
<span id="model-zoo-yolov8n-seg-coco-torch"></span><h3>yolov8n-seg-coco-torch<a class="headerlink" href="#yolov8n-seg-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv8n Segmentation model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8n-seg-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov8/">https://docs.ultralytics.com/models/yolov8/</a></p></li>
<li><p>Model size: 6.73 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8n-seg-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8s-coco-torch">
<span id="model-zoo-yolov8s-coco-torch"></span><h3>yolov8s-coco-torch<a class="headerlink" href="#yolov8s-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv8s model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8s-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov8/">https://docs.ultralytics.com/models/yolov8/</a></p></li>
<li><p>Model size: 21.53 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8s-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8s-obb-dotav1-torch">
<span id="model-zoo-yolov8s-obb-dotav1-torch"></span><h3>yolov8s-obb-dotav1-torch<a class="headerlink" href="#yolov8s-obb-dotav1-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv8s Oriented Bounding Box model.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8s-obb-dotav1-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/tasks/obb/">https://docs.ultralytics.com/tasks/obb/</a></p></li>
<li><p>Model size: 22.17 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">torch,</span> <span class="pre">yolo,</span> <span class="pre">polylines,</span> <span class="pre">obb</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.1.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8s-obb-dotav1-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8s-oiv7-torch">
<span id="model-zoo-yolov8s-oiv7-torch"></span><h3>yolov8s-oiv7-torch<a class="headerlink" href="#yolov8s-oiv7-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv8s model trained on Open Images v7.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8s-oiv7-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/datasets/detect/open-images-v7">https://docs.ultralytics.com/datasets/detect/open-images-v7</a></p></li>
<li><p>Model size: 21.53 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">oiv7,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8s-oiv7-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8s-seg-coco-torch">
<span id="model-zoo-yolov8s-seg-coco-torch"></span><h3>yolov8s-seg-coco-torch<a class="headerlink" href="#yolov8s-seg-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv8s Segmentation model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8s-seg-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov8/">https://docs.ultralytics.com/models/yolov8/</a></p></li>
<li><p>Model size: 22.79 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8s-seg-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8s-world-torch">
<span id="model-zoo-yolov8s-world-torch"></span><h3>yolov8s-world-torch<a class="headerlink" href="#yolov8s-world-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv8s-World model.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8s-world-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolo-world/">https://docs.ultralytics.com/models/yolo-world/</a></p></li>
<li><p>Model size: 25.91 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">torch,</span> <span class="pre">yolo,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.1.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8s-world-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8x-coco-torch">
<span id="model-zoo-yolov8x-coco-torch"></span><h3>yolov8x-coco-torch<a class="headerlink" href="#yolov8x-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv8x model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8x-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov8/">https://docs.ultralytics.com/models/yolov8/</a></p></li>
<li><p>Model size: 130.53 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8x-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8x-obb-dotav1-torch">
<span id="model-zoo-yolov8x-obb-dotav1-torch"></span><h3>yolov8x-obb-dotav1-torch<a class="headerlink" href="#yolov8x-obb-dotav1-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv8x Oriented Bounding Box model.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8x-obb-dotav1-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/tasks/obb/">https://docs.ultralytics.com/tasks/obb/</a></p></li>
<li><p>Model size: 133.07 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">torch,</span> <span class="pre">yolo,</span> <span class="pre">polylines,</span> <span class="pre">obb</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.1.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8x-obb-dotav1-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8x-oiv7-torch">
<span id="model-zoo-yolov8x-oiv7-torch"></span><h3>yolov8x-oiv7-torch<a class="headerlink" href="#yolov8x-oiv7-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv8x model trained Open Images v7.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8x-oiv7-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/datasets/detect/open-images-v7">https://docs.ultralytics.com/datasets/detect/open-images-v7</a></p></li>
<li><p>Model size: 130.53 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">oiv7,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8x-oiv7-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8x-seg-coco-torch">
<span id="model-zoo-yolov8x-seg-coco-torch"></span><h3>yolov8x-seg-coco-torch<a class="headerlink" href="#yolov8x-seg-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Ultralytics YOLOv8x Segmentation model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8x-seg-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov8/">https://docs.ultralytics.com/models/yolov8/</a></p></li>
<li><p>Model size: 137.40 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8x-seg-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov8x-world-torch">
<span id="model-zoo-yolov8x-world-torch"></span><h3>yolov8x-world-torch<a class="headerlink" href="#yolov8x-world-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv8x-World model.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov8x-world-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolo-world/">https://docs.ultralytics.com/models/yolo-world/</a></p></li>
<li><p>Model size: 141.11 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">torch,</span> <span class="pre">yolo,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.1.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov8x-world-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov9c-coco-torch">
<span id="model-zoo-yolov9c-coco-torch"></span><h3>yolov9c-coco-torch<a class="headerlink" href="#yolov9c-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv9-C model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov9c-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov9/">https://docs.ultralytics.com/models/yolov9/</a></p></li>
<li><p>Model size: 49.40 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.1.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov9c-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov9c-seg-coco-torch">
<span id="model-zoo-yolov9c-seg-coco-torch"></span><h3>yolov9c-seg-coco-torch<a class="headerlink" href="#yolov9c-seg-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv9-C Segmentation model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov9c-seg-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov9/#__tabbed_1_2">https://docs.ultralytics.com/models/yolov9/#__tabbed_1_2</a></p></li>
<li><p>Model size: 107.20 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.1.42</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov9c-seg-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov9e-coco-torch">
<span id="model-zoo-yolov9e-coco-torch"></span><h3>yolov9e-coco-torch<a class="headerlink" href="#yolov9e-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv9-E model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov9e-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov9/">https://docs.ultralytics.com/models/yolov9/</a></p></li>
<li><p>Model size: 112.09 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.1.0</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov9e-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolov9e-seg-coco-torch">
<span id="model-zoo-yolov9e-seg-coco-torch"></span><h3>yolov9e-seg-coco-torch<a class="headerlink" href="#yolov9e-seg-coco-torch" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv9-E Segmentation model trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolov9e-seg-coco-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://docs.ultralytics.com/models/yolov9/#__tabbed_1_2">https://docs.ultralytics.com/models/yolov9/#__tabbed_1_2</a></p></li>
<li><p>Model size: 232.20 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">coco,</span> <span class="pre">torch,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.7.0,</span> <span class="pre">torchvision&gt;=0.8.1,</span> <span class="pre">ultralytics&gt;=8.1.42</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolov9e-seg-coco-torch&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="zero-shot-classification-transformer-torch">
<span id="model-zoo-zero-shot-classification-transformer-torch"></span><h3>zero-shot-classification-transformer-torch<a class="headerlink" href="#zero-shot-classification-transformer-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Hugging Face Transformers model for zero-shot image classification.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">zero-shot-classification-transformer-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://huggingface.co/docs/transformers/tasks/zero_shot_image_classification">https://huggingface.co/docs/transformers/tasks/zero_shot_image_classification</a></p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">logits,</span> <span class="pre">embeddings,</span> <span class="pre">torch,</span> <span class="pre">transformers,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision,</span> <span class="pre">transformers</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span>
    <span class="s2">&quot;zero-shot-classification-transformer-torch&quot;</span><span class="p">,</span>
    <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;person&quot;</span><span class="p">,</span> <span class="s2">&quot;dog&quot;</span><span class="p">,</span> <span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;bird&quot;</span><span class="p">,</span> <span class="s2">&quot;car&quot;</span><span class="p">,</span> <span class="s2">&quot;tree&quot;</span><span class="p">,</span> <span class="s2">&quot;chair&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="zero-shot-detection-transformer-torch">
<span id="model-zoo-zero-shot-detection-transformer-torch"></span><h3>zero-shot-detection-transformer-torch<a class="headerlink" href="#zero-shot-detection-transformer-torch" title="Permalink to this headline">Â¶</a></h3>
<p>Hugging Face Transformers model for zero-shot object detection.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">zero-shot-detection-transformer-torch</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://huggingface.co/docs/transformers/tasks/zero_shot_object_detection">https://huggingface.co/docs/transformers/tasks/zero_shot_object_detection</a></p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">logits,</span> <span class="pre">embeddings,</span> <span class="pre">torch,</span> <span class="pre">transformers,</span> <span class="pre">zero-shot</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">torch,</span> <span class="pre">torchvision,</span> <span class="pre">transformers</span></code></p></li>
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span>
    <span class="s2">&quot;zero-shot-detection-transformer-torch&quot;</span><span class="p">,</span>
    <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;person&quot;</span><span class="p">,</span> <span class="s2">&quot;dog&quot;</span><span class="p">,</span> <span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;bird&quot;</span><span class="p">,</span> <span class="s2">&quot;car&quot;</span><span class="p">,</span> <span class="s2">&quot;tree&quot;</span><span class="p">,</span> <span class="s2">&quot;chair&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="tensorflow-models">
<span id="model-zoo-tensorflow-models"></span><h2>TensorFlow models<a class="headerlink" href="#tensorflow-models" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="centernet-hg104-1024-coco-tf2">
<span id="model-zoo-centernet-hg104-1024-coco-tf2"></span><h3>centernet-hg104-1024-coco-tf2<a class="headerlink" href="#centernet-hg104-1024-coco-tf2" title="Permalink to this headline">Â¶</a></h3>
<p>CenterNet model from <a class="reference external" href="https://arxiv.org/abs/1904.07850">Objects as Points</a> with the Hourglass-104 backbone trained on COCO resized to 1024x1024.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">centernet-hg104-1024-coco-tf2</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md</a></p></li>
<li><p>Model size: 1.33 GB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf2,</span> <span class="pre">centernet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=2|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;centernet-hg104-1024-coco-tf2&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="centernet-hg104-512-coco-tf2">
<span id="model-zoo-centernet-hg104-512-coco-tf2"></span><h3>centernet-hg104-512-coco-tf2<a class="headerlink" href="#centernet-hg104-512-coco-tf2" title="Permalink to this headline">Â¶</a></h3>
<p>CenterNet model from <a class="reference external" href="https://arxiv.org/abs/1904.07850">Objects as Points</a> with the Hourglass-104 backbone trained on COCO resized to 512x512.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">centernet-hg104-512-coco-tf2</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md</a></p></li>
<li><p>Model size: 1.49 GB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf2,</span> <span class="pre">centernet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=2|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;centernet-hg104-512-coco-tf2&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="centernet-mobilenet-v2-fpn-512-coco-tf2">
<span id="model-zoo-centernet-mobilenet-v2-fpn-512-coco-tf2"></span><h3>centernet-mobilenet-v2-fpn-512-coco-tf2<a class="headerlink" href="#centernet-mobilenet-v2-fpn-512-coco-tf2" title="Permalink to this headline">Â¶</a></h3>
<p>CenterNet model from <a class="reference external" href="https://arxiv.org/abs/1904.07850">Objects as Points</a> with the MobileNetV2 backbone trained on COCO resized to 512x512.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">centernet-mobilenet-v2-fpn-512-coco-tf2</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md</a></p></li>
<li><p>Model size: 41.98 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf2,</span> <span class="pre">centernet,</span> <span class="pre">mobilenet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=2|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;centernet-mobilenet-v2-fpn-512-coco-tf2&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="centernet-resnet101-v1-fpn-512-coco-tf2">
<span id="model-zoo-centernet-resnet101-v1-fpn-512-coco-tf2"></span><h3>centernet-resnet101-v1-fpn-512-coco-tf2<a class="headerlink" href="#centernet-resnet101-v1-fpn-512-coco-tf2" title="Permalink to this headline">Â¶</a></h3>
<p>CenterNet model from <a class="reference external" href="https://arxiv.org/abs/1904.07850">Objects as Points</a> with the ResNet-101v1 backbone + FPN trained on COCO resized to 512x512.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">centernet-resnet101-v1-fpn-512-coco-tf2</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md</a></p></li>
<li><p>Model size: 329.96 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf2,</span> <span class="pre">centernet,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=2|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;centernet-resnet101-v1-fpn-512-coco-tf2&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="centernet-resnet50-v1-fpn-512-coco-tf2">
<span id="model-zoo-centernet-resnet50-v1-fpn-512-coco-tf2"></span><h3>centernet-resnet50-v1-fpn-512-coco-tf2<a class="headerlink" href="#centernet-resnet50-v1-fpn-512-coco-tf2" title="Permalink to this headline">Â¶</a></h3>
<p>CenterNet model from <a class="reference external" href="https://arxiv.org/abs/1904.07850">Objects as Points</a> with the ResNet-50-v1 backbone + FPN trained on COCO resized to 512x512.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">centernet-resnet50-v1-fpn-512-coco-tf2</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md</a></p></li>
<li><p>Model size: 194.61 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf2,</span> <span class="pre">centernet,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=2|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;centernet-resnet50-v1-fpn-512-coco-tf2&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="centernet-resnet50-v2-512-coco-tf2">
<span id="model-zoo-centernet-resnet50-v2-512-coco-tf2"></span><h3>centernet-resnet50-v2-512-coco-tf2<a class="headerlink" href="#centernet-resnet50-v2-512-coco-tf2" title="Permalink to this headline">Â¶</a></h3>
<p>CenterNet model from <a class="reference external" href="https://arxiv.org/abs/1904.07850">Objects as Points</a> with the ResNet-50v2 backbone trained on COCO resized to 512x512.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">centernet-resnet50-v2-512-coco-tf2</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md</a></p></li>
<li><p>Model size: 226.95 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf2,</span> <span class="pre">centernet,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=2|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;centernet-resnet50-v2-512-coco-tf2&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="deeplabv3-cityscapes-tf">
<span id="model-zoo-deeplabv3-cityscapes-tf"></span><h3>deeplabv3-cityscapes-tf<a class="headerlink" href="#deeplabv3-cityscapes-tf" title="Permalink to this headline">Â¶</a></h3>
<p>DeepLabv3+ semantic segmentation model from <a class="reference external" href="https://arxiv.org/abs/1802.02611">Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation</a> with Xception backbone trained on the Cityscapes dataset.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">deeplabv3-cityscapes-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md">https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md</a></p></li>
<li><p>Model size: 158.04 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">cityscapes,</span> <span class="pre">tf,</span> <span class="pre">deeplabv3</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;deeplabv3-cityscapes-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="deeplabv3-mnv2-cityscapes-tf">
<span id="model-zoo-deeplabv3-mnv2-cityscapes-tf"></span><h3>deeplabv3-mnv2-cityscapes-tf<a class="headerlink" href="#deeplabv3-mnv2-cityscapes-tf" title="Permalink to this headline">Â¶</a></h3>
<p>DeepLabv3+ semantic segmentation model from <a class="reference external" href="https://arxiv.org/abs/1802.02611">Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation</a> with MobileNetV2 backbone trained on the Cityscapes dataset.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">deeplabv3-mnv2-cityscapes-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md">https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md</a></p></li>
<li><p>Model size: 8.37 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">segmentation,</span> <span class="pre">cityscapes,</span> <span class="pre">tf,</span> <span class="pre">deeplabv3</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;deeplabv3-mnv2-cityscapes-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="efficientdet-d0-512-coco-tf2">
<span id="model-zoo-efficientdet-d0-512-coco-tf2"></span><h3>efficientdet-d0-512-coco-tf2<a class="headerlink" href="#efficientdet-d0-512-coco-tf2" title="Permalink to this headline">Â¶</a></h3>
<p>EfficientDet-D0 model from <a class="reference external" href="https://arxiv.org/abs/1911.09070">EfficientDet: Scalable and Efficient Object Detection</a> trained on COCO resized to 512x512.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">efficientdet-d0-512-coco-tf2</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md</a></p></li>
<li><p>Model size: 29.31 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf2,</span> <span class="pre">efficientdet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=2|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;efficientdet-d0-512-coco-tf2&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="efficientdet-d0-coco-tf1">
<span id="model-zoo-efficientdet-d0-coco-tf1"></span><h3>efficientdet-d0-coco-tf1<a class="headerlink" href="#efficientdet-d0-coco-tf1" title="Permalink to this headline">Â¶</a></h3>
<p>EfficientDet-D0 model from <a class="reference external" href="https://arxiv.org/abs/1911.09070">EfficientDet: Scalable and Efficient Object Detection</a> trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">efficientdet-d0-coco-tf1</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/voxel51/automl/tree/master/efficientdet">https://github.com/voxel51/automl/tree/master/efficientdet</a></p></li>
<li><p>Model size: 38.20 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf1,</span> <span class="pre">efficientdet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=1.14,&lt;2</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=1.14,&lt;2</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;efficientdet-d0-coco-tf1&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="efficientdet-d1-640-coco-tf2">
<span id="model-zoo-efficientdet-d1-640-coco-tf2"></span><h3>efficientdet-d1-640-coco-tf2<a class="headerlink" href="#efficientdet-d1-640-coco-tf2" title="Permalink to this headline">Â¶</a></h3>
<p>EfficientDet-D1 model from <a class="reference external" href="https://arxiv.org/abs/1911.09070">EfficientDet: Scalable and Efficient Object Detection</a> trained on COCO resized to 640x640.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">efficientdet-d1-640-coco-tf2</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md</a></p></li>
<li><p>Model size: 49.44 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf2,</span> <span class="pre">efficientdet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=2|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;efficientdet-d1-640-coco-tf2&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="efficientdet-d1-coco-tf1">
<span id="model-zoo-efficientdet-d1-coco-tf1"></span><h3>efficientdet-d1-coco-tf1<a class="headerlink" href="#efficientdet-d1-coco-tf1" title="Permalink to this headline">Â¶</a></h3>
<p>EfficientDet-D1 model from <a class="reference external" href="https://arxiv.org/abs/1911.09070">EfficientDet: Scalable and Efficient Object Detection</a> trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">efficientdet-d1-coco-tf1</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/voxel51/automl/tree/master/efficientdet">https://github.com/voxel51/automl/tree/master/efficientdet</a></p></li>
<li><p>Model size: 61.64 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf1,</span> <span class="pre">efficientdet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=1.14,&lt;2</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=1.14,&lt;2</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;efficientdet-d1-coco-tf1&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="efficientdet-d2-768-coco-tf2">
<span id="model-zoo-efficientdet-d2-768-coco-tf2"></span><h3>efficientdet-d2-768-coco-tf2<a class="headerlink" href="#efficientdet-d2-768-coco-tf2" title="Permalink to this headline">Â¶</a></h3>
<p>EfficientDet-D2 model from <a class="reference external" href="https://arxiv.org/abs/1911.09070">EfficientDet: Scalable and Efficient Object Detection</a> trained on COCO resized to 768x768.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">efficientdet-d2-768-coco-tf2</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md</a></p></li>
<li><p>Model size: 60.01 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf2,</span> <span class="pre">efficientdet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=2|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;efficientdet-d2-768-coco-tf2&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="efficientdet-d2-coco-tf1">
<span id="model-zoo-efficientdet-d2-coco-tf1"></span><h3>efficientdet-d2-coco-tf1<a class="headerlink" href="#efficientdet-d2-coco-tf1" title="Permalink to this headline">Â¶</a></h3>
<p>EfficientDet-D2 model from <a class="reference external" href="https://arxiv.org/abs/1911.09070">EfficientDet: Scalable and Efficient Object Detection</a> trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">efficientdet-d2-coco-tf1</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/voxel51/automl/tree/master/efficientdet">https://github.com/voxel51/automl/tree/master/efficientdet</a></p></li>
<li><p>Model size: 74.00 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf1,</span> <span class="pre">efficientdet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=1.14,&lt;2</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=1.14,&lt;2</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;efficientdet-d2-coco-tf1&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="efficientdet-d3-896-coco-tf2">
<span id="model-zoo-efficientdet-d3-896-coco-tf2"></span><h3>efficientdet-d3-896-coco-tf2<a class="headerlink" href="#efficientdet-d3-896-coco-tf2" title="Permalink to this headline">Â¶</a></h3>
<p>EfficientDet-D3 model from <a class="reference external" href="https://arxiv.org/abs/1911.09070">EfficientDet: Scalable and Efficient Object Detection</a> trained on COCO resized to 896x896.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">efficientdet-d3-896-coco-tf2</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md</a></p></li>
<li><p>Model size: 88.56 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf2,</span> <span class="pre">efficientdet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=2|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;efficientdet-d3-896-coco-tf2&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="efficientdet-d3-coco-tf1">
<span id="model-zoo-efficientdet-d3-coco-tf1"></span><h3>efficientdet-d3-coco-tf1<a class="headerlink" href="#efficientdet-d3-coco-tf1" title="Permalink to this headline">Â¶</a></h3>
<p>EfficientDet-D3 model from <a class="reference external" href="https://arxiv.org/abs/1911.09070">EfficientDet: Scalable and Efficient Object Detection</a> trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">efficientdet-d3-coco-tf1</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/voxel51/automl/tree/master/efficientdet">https://github.com/voxel51/automl/tree/master/efficientdet</a></p></li>
<li><p>Model size: 106.44 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf1,</span> <span class="pre">efficientdet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=1.14,&lt;2</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=1.14,&lt;2</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;efficientdet-d3-coco-tf1&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="efficientdet-d4-1024-coco-tf2">
<span id="model-zoo-efficientdet-d4-1024-coco-tf2"></span><h3>efficientdet-d4-1024-coco-tf2<a class="headerlink" href="#efficientdet-d4-1024-coco-tf2" title="Permalink to this headline">Â¶</a></h3>
<p>EfficientDet-D4 model from <a class="reference external" href="https://arxiv.org/abs/1911.09070">EfficientDet: Scalable and Efficient Object Detection</a> trained on COCO resized to 1024x1024.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">efficientdet-d4-1024-coco-tf2</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md</a></p></li>
<li><p>Model size: 151.15 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf2,</span> <span class="pre">efficientdet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=2|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;efficientdet-d4-1024-coco-tf2&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="efficientdet-d4-coco-tf1">
<span id="model-zoo-efficientdet-d4-coco-tf1"></span><h3>efficientdet-d4-coco-tf1<a class="headerlink" href="#efficientdet-d4-coco-tf1" title="Permalink to this headline">Â¶</a></h3>
<p>EfficientDet-D4 model from <a class="reference external" href="https://arxiv.org/abs/1911.09070">EfficientDet: Scalable and Efficient Object Detection</a> trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">efficientdet-d4-coco-tf1</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/voxel51/automl/tree/master/efficientdet">https://github.com/voxel51/automl/tree/master/efficientdet</a></p></li>
<li><p>Model size: 175.33 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf1,</span> <span class="pre">efficientdet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=1.14,&lt;2</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=1.14,&lt;2</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;efficientdet-d4-coco-tf1&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="efficientdet-d5-1280-coco-tf2">
<span id="model-zoo-efficientdet-d5-1280-coco-tf2"></span><h3>efficientdet-d5-1280-coco-tf2<a class="headerlink" href="#efficientdet-d5-1280-coco-tf2" title="Permalink to this headline">Â¶</a></h3>
<p>EfficientDet-D5 model from <a class="reference external" href="https://arxiv.org/abs/1911.09070">EfficientDet: Scalable and Efficient Object Detection</a> trained on COCO resized to 1280x1280.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">efficientdet-d5-1280-coco-tf2</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md</a></p></li>
<li><p>Model size: 244.41 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf2,</span> <span class="pre">efficientdet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=2|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;efficientdet-d5-1280-coco-tf2&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="efficientdet-d5-coco-tf1">
<span id="model-zoo-efficientdet-d5-coco-tf1"></span><h3>efficientdet-d5-coco-tf1<a class="headerlink" href="#efficientdet-d5-coco-tf1" title="Permalink to this headline">Â¶</a></h3>
<p>EfficientDet-D5 model from <a class="reference external" href="https://arxiv.org/abs/1911.09070">EfficientDet: Scalable and Efficient Object Detection</a> trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">efficientdet-d5-coco-tf1</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/voxel51/automl/tree/master/efficientdet">https://github.com/voxel51/automl/tree/master/efficientdet</a></p></li>
<li><p>Model size: 275.81 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf1,</span> <span class="pre">efficientdet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=1.14,&lt;2</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=1.14,&lt;2</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;efficientdet-d5-coco-tf1&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="efficientdet-d6-1280-coco-tf2">
<span id="model-zoo-efficientdet-d6-1280-coco-tf2"></span><h3>efficientdet-d6-1280-coco-tf2<a class="headerlink" href="#efficientdet-d6-1280-coco-tf2" title="Permalink to this headline">Â¶</a></h3>
<p>EfficientDet-D6 model from <a class="reference external" href="https://arxiv.org/abs/1911.09070">EfficientDet: Scalable and Efficient Object Detection</a> trained on COCO resized to 1280x1280.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">efficientdet-d6-1280-coco-tf2</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md</a></p></li>
<li><p>Model size: 375.63 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf2,</span> <span class="pre">efficientdet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=2|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;efficientdet-d6-1280-coco-tf2&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="efficientdet-d6-coco-tf1">
<span id="model-zoo-efficientdet-d6-coco-tf1"></span><h3>efficientdet-d6-coco-tf1<a class="headerlink" href="#efficientdet-d6-coco-tf1" title="Permalink to this headline">Â¶</a></h3>
<p>EfficientDet-D6 model from <a class="reference external" href="https://arxiv.org/abs/1911.09070">EfficientDet: Scalable and Efficient Object Detection</a> trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">efficientdet-d6-coco-tf1</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/voxel51/automl/tree/master/efficientdet">https://github.com/voxel51/automl/tree/master/efficientdet</a></p></li>
<li><p>Model size: 416.43 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf1,</span> <span class="pre">efficientdet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=1.14,&lt;2</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=1.14,&lt;2</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;efficientdet-d6-coco-tf1&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="efficientdet-d7-1536-coco-tf2">
<span id="model-zoo-efficientdet-d7-1536-coco-tf2"></span><h3>efficientdet-d7-1536-coco-tf2<a class="headerlink" href="#efficientdet-d7-1536-coco-tf2" title="Permalink to this headline">Â¶</a></h3>
<p>EfficientDet-D7 model from <a class="reference external" href="https://arxiv.org/abs/1911.09070">EfficientDet: Scalable and Efficient Object Detection</a> trained on COCO resized to 1536x1536.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">efficientdet-d7-1536-coco-tf2</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md</a></p></li>
<li><p>Model size: 376.20 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf2,</span> <span class="pre">efficientdet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=2|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;efficientdet-d7-1536-coco-tf2&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="faster-rcnn-inception-resnet-atrous-v2-coco-tf">
<span id="model-zoo-faster-rcnn-inception-resnet-atrous-v2-coco-tf"></span><h3>faster-rcnn-inception-resnet-atrous-v2-coco-tf<a class="headerlink" href="#faster-rcnn-inception-resnet-atrous-v2-coco-tf" title="Permalink to this headline">Â¶</a></h3>
<p>Faster R-CNN model from <a class="reference external" href="https://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a> atrous version with Inception backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">faster-rcnn-inception-resnet-atrous-v2-coco-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md</a></p></li>
<li><p>Model size: 234.46 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf,</span> <span class="pre">faster-rcnn,</span> <span class="pre">inception,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;faster-rcnn-inception-resnet-atrous-v2-coco-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="faster-rcnn-inception-resnet-atrous-v2-lowproposals-coco-tf">
<span id="model-zoo-faster-rcnn-inception-resnet-atrous-v2-lowproposals-coco-tf"></span><h3>faster-rcnn-inception-resnet-atrous-v2-lowproposals-coco-tf<a class="headerlink" href="#faster-rcnn-inception-resnet-atrous-v2-lowproposals-coco-tf" title="Permalink to this headline">Â¶</a></h3>
<p>Faster R-CNN model from <a class="reference external" href="https://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a> atrous version with low-proposals and Inception backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">faster-rcnn-inception-resnet-atrous-v2-lowproposals-coco-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md</a></p></li>
<li><p>Model size: 234.46 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf,</span> <span class="pre">faster-rcnn,</span> <span class="pre">inception,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;faster-rcnn-inception-resnet-atrous-v2-lowproposals-coco-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="faster-rcnn-inception-v2-coco-tf">
<span id="model-zoo-faster-rcnn-inception-v2-coco-tf"></span><h3>faster-rcnn-inception-v2-coco-tf<a class="headerlink" href="#faster-rcnn-inception-v2-coco-tf" title="Permalink to this headline">Â¶</a></h3>
<p>Faster R-CNN model from <a class="reference external" href="https://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a> with Inception v2 backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">faster-rcnn-inception-v2-coco-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md</a></p></li>
<li><p>Model size: 52.97 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf,</span> <span class="pre">faster-rcnn,</span> <span class="pre">inception</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;faster-rcnn-inception-v2-coco-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="faster-rcnn-nas-coco-tf">
<span id="model-zoo-faster-rcnn-nas-coco-tf"></span><h3>faster-rcnn-nas-coco-tf<a class="headerlink" href="#faster-rcnn-nas-coco-tf" title="Permalink to this headline">Â¶</a></h3>
<p>Faster R-CNN model from <a class="reference external" href="https://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a> with NAS-net backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">faster-rcnn-nas-coco-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md</a></p></li>
<li><p>Model size: 404.95 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf,</span> <span class="pre">faster-rcnn</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;faster-rcnn-nas-coco-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="faster-rcnn-nas-lowproposals-coco-tf">
<span id="model-zoo-faster-rcnn-nas-lowproposals-coco-tf"></span><h3>faster-rcnn-nas-lowproposals-coco-tf<a class="headerlink" href="#faster-rcnn-nas-lowproposals-coco-tf" title="Permalink to this headline">Â¶</a></h3>
<p>Faster R-CNN model from <a class="reference external" href="https://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a> with low-proposals and NAS-net backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">faster-rcnn-nas-lowproposals-coco-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md</a></p></li>
<li><p>Model size: 404.88 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf,</span> <span class="pre">faster-rcnn</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;faster-rcnn-nas-lowproposals-coco-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="faster-rcnn-resnet101-coco-tf">
<span id="model-zoo-faster-rcnn-resnet101-coco-tf"></span><h3>faster-rcnn-resnet101-coco-tf<a class="headerlink" href="#faster-rcnn-resnet101-coco-tf" title="Permalink to this headline">Â¶</a></h3>
<p>Faster R-CNN model from <a class="reference external" href="https://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a> with ResNet-101 backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">faster-rcnn-resnet101-coco-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md</a></p></li>
<li><p>Model size: 186.41 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf,</span> <span class="pre">faster-rcnn,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;faster-rcnn-resnet101-coco-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="faster-rcnn-resnet101-lowproposals-coco-tf">
<span id="model-zoo-faster-rcnn-resnet101-lowproposals-coco-tf"></span><h3>faster-rcnn-resnet101-lowproposals-coco-tf<a class="headerlink" href="#faster-rcnn-resnet101-lowproposals-coco-tf" title="Permalink to this headline">Â¶</a></h3>
<p>Faster R-CNN model from <a class="reference external" href="https://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a> with low-proposals and ResNet-101 backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">faster-rcnn-resnet101-lowproposals-coco-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md</a></p></li>
<li><p>Model size: 186.41 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf,</span> <span class="pre">faster-rcnn,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;faster-rcnn-resnet101-lowproposals-coco-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="faster-rcnn-resnet50-coco-tf">
<span id="model-zoo-faster-rcnn-resnet50-coco-tf"></span><h3>faster-rcnn-resnet50-coco-tf<a class="headerlink" href="#faster-rcnn-resnet50-coco-tf" title="Permalink to this headline">Â¶</a></h3>
<p>Faster R-CNN model from <a class="reference external" href="https://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a> with ResNet-50 backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">faster-rcnn-resnet50-coco-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md</a></p></li>
<li><p>Model size: 113.57 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf,</span> <span class="pre">faster-rcnn,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;faster-rcnn-resnet50-coco-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="faster-rcnn-resnet50-lowproposals-coco-tf">
<span id="model-zoo-faster-rcnn-resnet50-lowproposals-coco-tf"></span><h3>faster-rcnn-resnet50-lowproposals-coco-tf<a class="headerlink" href="#faster-rcnn-resnet50-lowproposals-coco-tf" title="Permalink to this headline">Â¶</a></h3>
<p>Faster R-CNN model from <a class="reference external" href="https://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a> with low-proposals and ResNet-50 backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">faster-rcnn-resnet50-lowproposals-coco-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md</a></p></li>
<li><p>Model size: 113.57 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf,</span> <span class="pre">faster-rcnn,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;faster-rcnn-resnet50-lowproposals-coco-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="inception-resnet-v2-imagenet-tf1">
<span id="model-zoo-inception-resnet-v2-imagenet-tf1"></span><h3>inception-resnet-v2-imagenet-tf1<a class="headerlink" href="#inception-resnet-v2-imagenet-tf1" title="Permalink to this headline">Â¶</a></h3>
<p>Inception v2 model from <a class="reference external" href="https://arxiv.org/abs/1512.00567">Rethinking the Inception Architecture for Computer Vision</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">inception-resnet-v2-imagenet-tf1</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/tree/archive/research/slim#pre-trained-models">https://github.com/tensorflow/models/tree/archive/research/slim#pre-trained-models</a></p></li>
<li><p>Model size: 213.81 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">tf1,</span> <span class="pre">inception,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&lt;2</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&lt;2</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;inception-resnet-v2-imagenet-tf1&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="inception-v4-imagenet-tf1">
<span id="model-zoo-inception-v4-imagenet-tf1"></span><h3>inception-v4-imagenet-tf1<a class="headerlink" href="#inception-v4-imagenet-tf1" title="Permalink to this headline">Â¶</a></h3>
<p>Inception v4 model from <a class="reference external" href="https://arxiv.org/abs/1602.07261">Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">inception-v4-imagenet-tf1</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/tree/archive/research/slim#pre-trained-models">https://github.com/tensorflow/models/tree/archive/research/slim#pre-trained-models</a></p></li>
<li><p>Model size: 163.31 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">tf1,</span> <span class="pre">inception</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&lt;2</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&lt;2</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;inception-v4-imagenet-tf1&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="mask-rcnn-inception-resnet-v2-atrous-coco-tf">
<span id="model-zoo-mask-rcnn-inception-resnet-v2-atrous-coco-tf"></span><h3>mask-rcnn-inception-resnet-v2-atrous-coco-tf<a class="headerlink" href="#mask-rcnn-inception-resnet-v2-atrous-coco-tf" title="Permalink to this headline">Â¶</a></h3>
<p>Mask R-CNN model from <a class="reference external" href="https://arxiv.org/abs/1703.06870">Mask R-CNN</a> atrous version with Inception backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">mask-rcnn-inception-resnet-v2-atrous-coco-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md</a></p></li>
<li><p>Model size: 254.51 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">instances,</span> <span class="pre">coco,</span> <span class="pre">tf,</span> <span class="pre">mask-rcnn,</span> <span class="pre">inception,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;mask-rcnn-inception-resnet-v2-atrous-coco-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="mask-rcnn-inception-v2-coco-tf">
<span id="model-zoo-mask-rcnn-inception-v2-coco-tf"></span><h3>mask-rcnn-inception-v2-coco-tf<a class="headerlink" href="#mask-rcnn-inception-v2-coco-tf" title="Permalink to this headline">Â¶</a></h3>
<p>Mask R-CNN model from <a class="reference external" href="https://arxiv.org/abs/1703.06870">Mask R-CNN</a> with Inception backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">mask-rcnn-inception-v2-coco-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md</a></p></li>
<li><p>Model size: 64.03 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">instances,</span> <span class="pre">coco,</span> <span class="pre">tf,</span> <span class="pre">mask-rcnn,</span> <span class="pre">inception</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;mask-rcnn-inception-v2-coco-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="mask-rcnn-resnet101-atrous-coco-tf">
<span id="model-zoo-mask-rcnn-resnet101-atrous-coco-tf"></span><h3>mask-rcnn-resnet101-atrous-coco-tf<a class="headerlink" href="#mask-rcnn-resnet101-atrous-coco-tf" title="Permalink to this headline">Â¶</a></h3>
<p>Mask R-CNN model from <a class="reference external" href="https://arxiv.org/abs/1703.06870">Mask R-CNN</a> atrous version with ResNet-101 backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">mask-rcnn-resnet101-atrous-coco-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md</a></p></li>
<li><p>Model size: 211.56 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">instances,</span> <span class="pre">coco,</span> <span class="pre">tf,</span> <span class="pre">mask-rcnn,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;mask-rcnn-resnet101-atrous-coco-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="mask-rcnn-resnet50-atrous-coco-tf">
<span id="model-zoo-mask-rcnn-resnet50-atrous-coco-tf"></span><h3>mask-rcnn-resnet50-atrous-coco-tf<a class="headerlink" href="#mask-rcnn-resnet50-atrous-coco-tf" title="Permalink to this headline">Â¶</a></h3>
<p>Mask R-CNN model from <a class="reference external" href="https://arxiv.org/abs/1703.06870">Mask R-CNN</a> atrous version with ResNet-50 backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">mask-rcnn-resnet50-atrous-coco-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md</a></p></li>
<li><p>Model size: 138.29 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">instances,</span> <span class="pre">coco,</span> <span class="pre">tf,</span> <span class="pre">mask-rcnn,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;mask-rcnn-resnet50-atrous-coco-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="mobilenet-v2-imagenet-tf1">
<span id="model-zoo-mobilenet-v2-imagenet-tf1"></span><h3>mobilenet-v2-imagenet-tf1<a class="headerlink" href="#mobilenet-v2-imagenet-tf1" title="Permalink to this headline">Â¶</a></h3>
<p>MobileNetV2 model from <a class="reference external" href="https://arxiv.org/abs/1801.04381">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">mobilenet-v2-imagenet-tf1</span></code></p></li>
<li><p>Model source: None</p></li>
<li><p>Model size: 13.64 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">tf1,</span> <span class="pre">mobilenet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&lt;2</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&lt;2</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;mobilenet-v2-imagenet-tf1&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="resnet-v1-50-imagenet-tf1">
<span id="model-zoo-resnet-v1-50-imagenet-tf1"></span><h3>resnet-v1-50-imagenet-tf1<a class="headerlink" href="#resnet-v1-50-imagenet-tf1" title="Permalink to this headline">Â¶</a></h3>
<p>ResNet-50 v1 model from <a class="reference external" href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">resnet-v1-50-imagenet-tf1</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/tree/archive/research/slim#pre-trained-models">https://github.com/tensorflow/models/tree/archive/research/slim#pre-trained-models</a></p></li>
<li><p>Model size: 97.84 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">tf1,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&lt;2</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&lt;2</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;resnet-v1-50-imagenet-tf1&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="resnet-v2-50-imagenet-tf1">
<span id="model-zoo-resnet-v2-50-imagenet-tf1"></span><h3>resnet-v2-50-imagenet-tf1<a class="headerlink" href="#resnet-v2-50-imagenet-tf1" title="Permalink to this headline">Â¶</a></h3>
<p>ResNet-50 v2 model from <a class="reference external" href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">resnet-v2-50-imagenet-tf1</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/tree/archive/research/slim#pre-trained-models">https://github.com/tensorflow/models/tree/archive/research/slim#pre-trained-models</a></p></li>
<li><p>Model size: 97.86 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">tf1,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&lt;2</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&lt;2</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;resnet-v2-50-imagenet-tf1&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="rfcn-resnet101-coco-tf">
<span id="model-zoo-rfcn-resnet101-coco-tf"></span><h3>rfcn-resnet101-coco-tf<a class="headerlink" href="#rfcn-resnet101-coco-tf" title="Permalink to this headline">Â¶</a></h3>
<p>R-FCN object detection model from <a class="reference external" href="https://arxiv.org/abs/1605.06409">R-FCN: Object Detection via Region-based Fully Convolutional Networks</a> with ResNet-101 backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">rfcn-resnet101-coco-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md</a></p></li>
<li><p>Model size: 208.16 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf,</span> <span class="pre">rfcn,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;rfcn-resnet101-coco-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="ssd-inception-v2-coco-tf">
<span id="model-zoo-ssd-inception-v2-coco-tf"></span><h3>ssd-inception-v2-coco-tf<a class="headerlink" href="#ssd-inception-v2-coco-tf" title="Permalink to this headline">Â¶</a></h3>
<p>Inception Single Shot Detector model from <a class="reference external" href="https://arxiv.org/abs/1512.02325">SSD: Single Shot MultiBox Detector</a> trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">ssd-inception-v2-coco-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md</a></p></li>
<li><p>Model size: 97.50 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf,</span> <span class="pre">ssd,</span> <span class="pre">inception</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;ssd-inception-v2-coco-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="ssd-mobilenet-v1-coco-tf">
<span id="model-zoo-ssd-mobilenet-v1-coco-tf"></span><h3>ssd-mobilenet-v1-coco-tf<a class="headerlink" href="#ssd-mobilenet-v1-coco-tf" title="Permalink to this headline">Â¶</a></h3>
<p>Single Shot Detector model from <a class="reference external" href="https://arxiv.org/abs/1512.02325">SSD: Single Shot MultiBox Detector</a> with MobileNetV1 backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">ssd-mobilenet-v1-coco-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md</a></p></li>
<li><p>Model size: 27.83 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf,</span> <span class="pre">ssd,</span> <span class="pre">mobilenet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;ssd-mobilenet-v1-coco-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="ssd-mobilenet-v1-fpn-640-coco17">
<span id="model-zoo-ssd-mobilenet-v1-fpn-640-coco17"></span><h3>ssd-mobilenet-v1-fpn-640-coco17<a class="headerlink" href="#ssd-mobilenet-v1-fpn-640-coco17" title="Permalink to this headline">Â¶</a></h3>
<p>MobileNetV1 model from <a class="reference external" href="https://arxiv.org/pdf/1801.04381.pdf">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a> resized to 640x640.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">ssd-mobilenet-v1-fpn-640-coco17</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md</a></p></li>
<li><p>Model size: 43.91 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf2,</span> <span class="pre">ssd,</span> <span class="pre">mobilenet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=2|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;ssd-mobilenet-v1-fpn-640-coco17&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="ssd-mobilenet-v1-fpn-coco-tf">
<span id="model-zoo-ssd-mobilenet-v1-fpn-coco-tf"></span><h3>ssd-mobilenet-v1-fpn-coco-tf<a class="headerlink" href="#ssd-mobilenet-v1-fpn-coco-tf" title="Permalink to this headline">Â¶</a></h3>
<p>FPN Single Shot Detector model from <a class="reference external" href="https://arxiv.org/abs/1512.02325">SSD: Single Shot MultiBox Detector</a> with MobileNetV1 backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">ssd-mobilenet-v1-fpn-coco-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md</a></p></li>
<li><p>Model size: 48.97 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf,</span> <span class="pre">ssd,</span> <span class="pre">mobilenet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;ssd-mobilenet-v1-fpn-coco-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="ssd-mobilenet-v2-320-coco17">
<span id="model-zoo-ssd-mobilenet-v2-320-coco17"></span><h3>ssd-mobilenet-v2-320-coco17<a class="headerlink" href="#ssd-mobilenet-v2-320-coco17" title="Permalink to this headline">Â¶</a></h3>
<p>MobileNetV2 model from <a class="reference external" href="https://arxiv.org/pdf/1801.04381.pdf">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a> resized to 320x320.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">ssd-mobilenet-v2-320-coco17</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf2_detection_zoo.md</a></p></li>
<li><p>Model size: 43.91 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf2,</span> <span class="pre">ssd,</span> <span class="pre">mobilenet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&gt;=2|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;ssd-mobilenet-v2-320-coco17&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="ssd-resnet50-fpn-coco-tf">
<span id="model-zoo-ssd-resnet50-fpn-coco-tf"></span><h3>ssd-resnet50-fpn-coco-tf<a class="headerlink" href="#ssd-resnet50-fpn-coco-tf" title="Permalink to this headline">Â¶</a></h3>
<p>FPN Single Shot Detector model from <a class="reference external" href="https://arxiv.org/abs/1512.02325">SSD: Single Shot MultiBox Detector</a> with ResNet-50 backbone trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">ssd-resnet50-fpn-coco-tf</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md">https://github.com/tensorflow/models/blob/archive/research/object_detection/g3doc/tf1_detection_zoo.md</a></p></li>
<li><p>Model size: 128.07 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf,</span> <span class="pre">ssd,</span> <span class="pre">resnet</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow|tensorflow-macos</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu|tensorflow&gt;=2|tensorflow-macos</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;ssd-resnet50-fpn-coco-tf&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="vgg16-imagenet-tf1">
<span id="model-zoo-vgg16-imagenet-tf1"></span><h3>vgg16-imagenet-tf1<a class="headerlink" href="#vgg16-imagenet-tf1" title="Permalink to this headline">Â¶</a></h3>
<p>VGG-16 model from <a class="reference external" href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a> trained on ImageNet.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">vgg16-imagenet-tf1</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://gist.github.com/ksimonyan/211839e770f7b538e2d8#file-readme-md">https://gist.github.com/ksimonyan/211839e770f7b538e2d8#file-readme-md</a></p></li>
<li><p>Model size: 527.80 MB</p></li>
<li><p>Exposes embeddings? yes</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">classification,</span> <span class="pre">embeddings,</span> <span class="pre">logits,</span> <span class="pre">imagenet,</span> <span class="pre">tf1,</span> <span class="pre">vgg</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&lt;2</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&lt;2</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;imagenet-sample&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;vgg16-imagenet-tf1&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="yolo-v2-coco-tf1">
<span id="model-zoo-yolo-v2-coco-tf1"></span><h3>yolo-v2-coco-tf1<a class="headerlink" href="#yolo-v2-coco-tf1" title="Permalink to this headline">Â¶</a></h3>
<p>YOLOv2 model from <a class="reference external" href="https://arxiv.org/abs/1612.08242">YOLO9000: Better, Faster, Stronger</a> trained on COCO.</p>
<p><strong>Details</strong></p>
<ul class="simple">
<li><p>Model name: <code class="docutils literal notranslate"><span class="pre">yolo-v2-coco-tf1</span></code></p></li>
<li><p>Model source: <a class="reference external" href="https://github.com/thtrieu/darkflow">https://github.com/thtrieu/darkflow</a></p></li>
<li><p>Model size: 194.49 MB</p></li>
<li><p>Exposes embeddings? no</p></li>
<li><p>Tags: <code class="docutils literal notranslate"><span class="pre">detection,</span> <span class="pre">coco,</span> <span class="pre">tf1,</span> <span class="pre">yolo</span></code></p></li>
</ul>
<p><strong>Requirements</strong></p>
<ul class="simple">
<li><p>CPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow&lt;2</span></code></p></li>
</ul>
</li>
<li><p>GPU support</p>
<ul>
<li><p>yes</p></li>
<li><p>Packages: <code class="docutils literal notranslate"><span class="pre">tensorflow-gpu&lt;2</span></code></p></li>
</ul>
</li>
</ul>
<p><strong>Example usage</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">fiftyone</span> <span class="k">as</span> <span class="nn">fo</span>
<span class="kn">import</span> <span class="nn">fiftyone.zoo</span> <span class="k">as</span> <span class="nn">foz</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_dataset</span><span class="p">(</span>
    <span class="s2">&quot;coco-2017&quot;</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">fo</span><span class="o">.</span><span class="n">get_default_dataset_name</span><span class="p">(),</span>
    <span class="n">max_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">foz</span><span class="o">.</span><span class="n">load_zoo_model</span><span class="p">(</span><span class="s2">&quot;yolo-v2-coco-tf1&quot;</span><span class="p">)</span>

<span class="n">dataset</span><span class="o">.</span><span class="n">apply_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">label_field</span><span class="o">=</span><span class="s2">&quot;predictions&quot;</span><span class="p">)</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">fo</span><span class="o">.</span><span class="n">launch_app</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="remote.html" class="btn btn-neutral float-right" title="Remotely-Sourced Zoo Models" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="FiftyOne Model Zoo" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  
</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Built-In Zoo Models</a><ul>
<li><a class="reference internal" href="#torch-models">Torch models</a><ul>
<li><a class="reference internal" href="#alexnet-imagenet-torch">alexnet-imagenet-torch</a></li>
<li><a class="reference internal" href="#classification-transformer-torch">classification-transformer-torch</a></li>
<li><a class="reference internal" href="#clip-vit-base32-torch">clip-vit-base32-torch</a></li>
<li><a class="reference internal" href="#deeplabv3-resnet101-coco-torch">deeplabv3-resnet101-coco-torch</a></li>
<li><a class="reference internal" href="#deeplabv3-resnet50-coco-torch">deeplabv3-resnet50-coco-torch</a></li>
<li><a class="reference internal" href="#densenet121-imagenet-torch">densenet121-imagenet-torch</a></li>
<li><a class="reference internal" href="#densenet161-imagenet-torch">densenet161-imagenet-torch</a></li>
<li><a class="reference internal" href="#densenet169-imagenet-torch">densenet169-imagenet-torch</a></li>
<li><a class="reference internal" href="#densenet201-imagenet-torch">densenet201-imagenet-torch</a></li>
<li><a class="reference internal" href="#depth-estimation-transformer-torch">depth-estimation-transformer-torch</a></li>
<li><a class="reference internal" href="#detection-transformer-torch">detection-transformer-torch</a></li>
<li><a class="reference internal" href="#dinov2-vitb14-reg-torch">dinov2-vitb14-reg-torch</a></li>
<li><a class="reference internal" href="#dinov2-vitb14-torch">dinov2-vitb14-torch</a></li>
<li><a class="reference internal" href="#dinov2-vitg14-reg-torch">dinov2-vitg14-reg-torch</a></li>
<li><a class="reference internal" href="#dinov2-vitg14-torch">dinov2-vitg14-torch</a></li>
<li><a class="reference internal" href="#dinov2-vitl14-reg-torch">dinov2-vitl14-reg-torch</a></li>
<li><a class="reference internal" href="#dinov2-vitl14-torch">dinov2-vitl14-torch</a></li>
<li><a class="reference internal" href="#dinov2-vits14-reg-torch">dinov2-vits14-reg-torch</a></li>
<li><a class="reference internal" href="#dinov2-vits14-torch">dinov2-vits14-torch</a></li>
<li><a class="reference internal" href="#faster-rcnn-resnet50-fpn-coco-torch">faster-rcnn-resnet50-fpn-coco-torch</a></li>
<li><a class="reference internal" href="#fcn-resnet101-coco-torch">fcn-resnet101-coco-torch</a></li>
<li><a class="reference internal" href="#fcn-resnet50-coco-torch">fcn-resnet50-coco-torch</a></li>
<li><a class="reference internal" href="#googlenet-imagenet-torch">googlenet-imagenet-torch</a></li>
<li><a class="reference internal" href="#inception-v3-imagenet-torch">inception-v3-imagenet-torch</a></li>
<li><a class="reference internal" href="#keypoint-rcnn-resnet50-fpn-coco-torch">keypoint-rcnn-resnet50-fpn-coco-torch</a></li>
<li><a class="reference internal" href="#mask-rcnn-resnet50-fpn-coco-torch">mask-rcnn-resnet50-fpn-coco-torch</a></li>
<li><a class="reference internal" href="#med-sam-2-video-torch">med-sam-2-video-torch</a></li>
<li><a class="reference internal" href="#mnasnet0-5-imagenet-torch">mnasnet0.5-imagenet-torch</a></li>
<li><a class="reference internal" href="#mnasnet1-0-imagenet-torch">mnasnet1.0-imagenet-torch</a></li>
<li><a class="reference internal" href="#mobilenet-v2-imagenet-torch">mobilenet-v2-imagenet-torch</a></li>
<li><a class="reference internal" href="#open-clip-torch">open-clip-torch</a></li>
<li><a class="reference internal" href="#resnet101-imagenet-torch">resnet101-imagenet-torch</a></li>
<li><a class="reference internal" href="#resnet152-imagenet-torch">resnet152-imagenet-torch</a></li>
<li><a class="reference internal" href="#resnet18-imagenet-torch">resnet18-imagenet-torch</a></li>
<li><a class="reference internal" href="#resnet34-imagenet-torch">resnet34-imagenet-torch</a></li>
<li><a class="reference internal" href="#resnet50-imagenet-torch">resnet50-imagenet-torch</a></li>
<li><a class="reference internal" href="#resnext101-32x8d-imagenet-torch">resnext101-32x8d-imagenet-torch</a></li>
<li><a class="reference internal" href="#resnext50-32x4d-imagenet-torch">resnext50-32x4d-imagenet-torch</a></li>
<li><a class="reference internal" href="#retinanet-resnet50-fpn-coco-torch">retinanet-resnet50-fpn-coco-torch</a></li>
<li><a class="reference internal" href="#rtdetr-l-coco-torch">rtdetr-l-coco-torch</a></li>
<li><a class="reference internal" href="#rtdetr-x-coco-torch">rtdetr-x-coco-torch</a></li>
<li><a class="reference internal" href="#segment-anything-2-hiera-base-plus-image-torch">segment-anything-2-hiera-base-plus-image-torch</a></li>
<li><a class="reference internal" href="#segment-anything-2-hiera-base-plus-video-torch">segment-anything-2-hiera-base-plus-video-torch</a></li>
<li><a class="reference internal" href="#segment-anything-2-hiera-large-image-torch">segment-anything-2-hiera-large-image-torch</a></li>
<li><a class="reference internal" href="#segment-anything-2-hiera-large-video-torch">segment-anything-2-hiera-large-video-torch</a></li>
<li><a class="reference internal" href="#segment-anything-2-hiera-small-image-torch">segment-anything-2-hiera-small-image-torch</a></li>
<li><a class="reference internal" href="#segment-anything-2-hiera-small-video-torch">segment-anything-2-hiera-small-video-torch</a></li>
<li><a class="reference internal" href="#segment-anything-2-hiera-tiny-image-torch">segment-anything-2-hiera-tiny-image-torch</a></li>
<li><a class="reference internal" href="#segment-anything-2-hiera-tiny-video-torch">segment-anything-2-hiera-tiny-video-torch</a></li>
<li><a class="reference internal" href="#segment-anything-2-1-hiera-base-plus-image-torch">segment-anything-2.1-hiera-base-plus-image-torch</a></li>
<li><a class="reference internal" href="#segment-anything-2-1-hiera-base-plus-video-torch">segment-anything-2.1-hiera-base-plus-video-torch</a></li>
<li><a class="reference internal" href="#segment-anything-2-1-hiera-large-image-torch">segment-anything-2.1-hiera-large-image-torch</a></li>
<li><a class="reference internal" href="#segment-anything-2-1-hiera-large-video-torch">segment-anything-2.1-hiera-large-video-torch</a></li>
<li><a class="reference internal" href="#segment-anything-2-1-hiera-small-image-torch">segment-anything-2.1-hiera-small-image-torch</a></li>
<li><a class="reference internal" href="#segment-anything-2-1-hiera-small-video-torch">segment-anything-2.1-hiera-small-video-torch</a></li>
<li><a class="reference internal" href="#segment-anything-2-1-hiera-tiny-image-torch">segment-anything-2.1-hiera-tiny-image-torch</a></li>
<li><a class="reference internal" href="#segment-anything-2-1-hiera-tiny-video-torch">segment-anything-2.1-hiera-tiny-video-torch</a></li>
<li><a class="reference internal" href="#segment-anything-vitb-torch">segment-anything-vitb-torch</a></li>
<li><a class="reference internal" href="#segment-anything-vith-torch">segment-anything-vith-torch</a></li>
<li><a class="reference internal" href="#segment-anything-vitl-torch">segment-anything-vitl-torch</a></li>
<li><a class="reference internal" href="#segmentation-transformer-torch">segmentation-transformer-torch</a></li>
<li><a class="reference internal" href="#shufflenetv2-0-5x-imagenet-torch">shufflenetv2-0.5x-imagenet-torch</a></li>
<li><a class="reference internal" href="#shufflenetv2-1-0x-imagenet-torch">shufflenetv2-1.0x-imagenet-torch</a></li>
<li><a class="reference internal" href="#squeezenet-1-1-imagenet-torch">squeezenet-1.1-imagenet-torch</a></li>
<li><a class="reference internal" href="#squeezenet-imagenet-torch">squeezenet-imagenet-torch</a></li>
<li><a class="reference internal" href="#vgg11-bn-imagenet-torch">vgg11-bn-imagenet-torch</a></li>
<li><a class="reference internal" href="#vgg11-imagenet-torch">vgg11-imagenet-torch</a></li>
<li><a class="reference internal" href="#vgg13-bn-imagenet-torch">vgg13-bn-imagenet-torch</a></li>
<li><a class="reference internal" href="#vgg13-imagenet-torch">vgg13-imagenet-torch</a></li>
<li><a class="reference internal" href="#vgg16-bn-imagenet-torch">vgg16-bn-imagenet-torch</a></li>
<li><a class="reference internal" href="#vgg16-imagenet-torch">vgg16-imagenet-torch</a></li>
<li><a class="reference internal" href="#vgg19-bn-imagenet-torch">vgg19-bn-imagenet-torch</a></li>
<li><a class="reference internal" href="#vgg19-imagenet-torch">vgg19-imagenet-torch</a></li>
<li><a class="reference internal" href="#wide-resnet101-2-imagenet-torch">wide-resnet101-2-imagenet-torch</a></li>
<li><a class="reference internal" href="#wide-resnet50-2-imagenet-torch">wide-resnet50-2-imagenet-torch</a></li>
<li><a class="reference internal" href="#yolo-nas-torch">yolo-nas-torch</a></li>
<li><a class="reference internal" href="#yolo11l-coco-torch">yolo11l-coco-torch</a></li>
<li><a class="reference internal" href="#yolo11l-seg-coco-torch">yolo11l-seg-coco-torch</a></li>
<li><a class="reference internal" href="#yolo11m-coco-torch">yolo11m-coco-torch</a></li>
<li><a class="reference internal" href="#yolo11m-seg-coco-torch">yolo11m-seg-coco-torch</a></li>
<li><a class="reference internal" href="#yolo11n-coco-torch">yolo11n-coco-torch</a></li>
<li><a class="reference internal" href="#yolo11n-seg-coco-torch">yolo11n-seg-coco-torch</a></li>
<li><a class="reference internal" href="#yolo11s-coco-torch">yolo11s-coco-torch</a></li>
<li><a class="reference internal" href="#yolo11s-seg-coco-torch">yolo11s-seg-coco-torch</a></li>
<li><a class="reference internal" href="#yolo11x-coco-torch">yolo11x-coco-torch</a></li>
<li><a class="reference internal" href="#yolo11x-seg-coco-torch">yolo11x-seg-coco-torch</a></li>
<li><a class="reference internal" href="#yolov10l-coco-torch">yolov10l-coco-torch</a></li>
<li><a class="reference internal" href="#yolov10m-coco-torch">yolov10m-coco-torch</a></li>
<li><a class="reference internal" href="#yolov10n-coco-torch">yolov10n-coco-torch</a></li>
<li><a class="reference internal" href="#yolov10s-coco-torch">yolov10s-coco-torch</a></li>
<li><a class="reference internal" href="#yolov10x-coco-torch">yolov10x-coco-torch</a></li>
<li><a class="reference internal" href="#yolov5l-coco-torch">yolov5l-coco-torch</a></li>
<li><a class="reference internal" href="#yolov5m-coco-torch">yolov5m-coco-torch</a></li>
<li><a class="reference internal" href="#yolov5n-coco-torch">yolov5n-coco-torch</a></li>
<li><a class="reference internal" href="#yolov5s-coco-torch">yolov5s-coco-torch</a></li>
<li><a class="reference internal" href="#yolov5x-coco-torch">yolov5x-coco-torch</a></li>
<li><a class="reference internal" href="#yolov8l-coco-torch">yolov8l-coco-torch</a></li>
<li><a class="reference internal" href="#yolov8l-obb-dotav1-torch">yolov8l-obb-dotav1-torch</a></li>
<li><a class="reference internal" href="#yolov8l-oiv7-torch">yolov8l-oiv7-torch</a></li>
<li><a class="reference internal" href="#yolov8l-seg-coco-torch">yolov8l-seg-coco-torch</a></li>
<li><a class="reference internal" href="#yolov8l-world-torch">yolov8l-world-torch</a></li>
<li><a class="reference internal" href="#yolov8m-coco-torch">yolov8m-coco-torch</a></li>
<li><a class="reference internal" href="#yolov8m-obb-dotav1-torch">yolov8m-obb-dotav1-torch</a></li>
<li><a class="reference internal" href="#yolov8m-oiv7-torch">yolov8m-oiv7-torch</a></li>
<li><a class="reference internal" href="#yolov8m-seg-coco-torch">yolov8m-seg-coco-torch</a></li>
<li><a class="reference internal" href="#yolov8m-world-torch">yolov8m-world-torch</a></li>
<li><a class="reference internal" href="#yolov8n-coco-torch">yolov8n-coco-torch</a></li>
<li><a class="reference internal" href="#yolov8n-obb-dotav1-torch">yolov8n-obb-dotav1-torch</a></li>
<li><a class="reference internal" href="#yolov8n-oiv7-torch">yolov8n-oiv7-torch</a></li>
<li><a class="reference internal" href="#yolov8n-seg-coco-torch">yolov8n-seg-coco-torch</a></li>
<li><a class="reference internal" href="#yolov8s-coco-torch">yolov8s-coco-torch</a></li>
<li><a class="reference internal" href="#yolov8s-obb-dotav1-torch">yolov8s-obb-dotav1-torch</a></li>
<li><a class="reference internal" href="#yolov8s-oiv7-torch">yolov8s-oiv7-torch</a></li>
<li><a class="reference internal" href="#yolov8s-seg-coco-torch">yolov8s-seg-coco-torch</a></li>
<li><a class="reference internal" href="#yolov8s-world-torch">yolov8s-world-torch</a></li>
<li><a class="reference internal" href="#yolov8x-coco-torch">yolov8x-coco-torch</a></li>
<li><a class="reference internal" href="#yolov8x-obb-dotav1-torch">yolov8x-obb-dotav1-torch</a></li>
<li><a class="reference internal" href="#yolov8x-oiv7-torch">yolov8x-oiv7-torch</a></li>
<li><a class="reference internal" href="#yolov8x-seg-coco-torch">yolov8x-seg-coco-torch</a></li>
<li><a class="reference internal" href="#yolov8x-world-torch">yolov8x-world-torch</a></li>
<li><a class="reference internal" href="#yolov9c-coco-torch">yolov9c-coco-torch</a></li>
<li><a class="reference internal" href="#yolov9c-seg-coco-torch">yolov9c-seg-coco-torch</a></li>
<li><a class="reference internal" href="#yolov9e-coco-torch">yolov9e-coco-torch</a></li>
<li><a class="reference internal" href="#yolov9e-seg-coco-torch">yolov9e-seg-coco-torch</a></li>
<li><a class="reference internal" href="#zero-shot-classification-transformer-torch">zero-shot-classification-transformer-torch</a></li>
<li><a class="reference internal" href="#zero-shot-detection-transformer-torch">zero-shot-detection-transformer-torch</a></li>
</ul>
</li>
<li><a class="reference internal" href="#tensorflow-models">TensorFlow models</a><ul>
<li><a class="reference internal" href="#centernet-hg104-1024-coco-tf2">centernet-hg104-1024-coco-tf2</a></li>
<li><a class="reference internal" href="#centernet-hg104-512-coco-tf2">centernet-hg104-512-coco-tf2</a></li>
<li><a class="reference internal" href="#centernet-mobilenet-v2-fpn-512-coco-tf2">centernet-mobilenet-v2-fpn-512-coco-tf2</a></li>
<li><a class="reference internal" href="#centernet-resnet101-v1-fpn-512-coco-tf2">centernet-resnet101-v1-fpn-512-coco-tf2</a></li>
<li><a class="reference internal" href="#centernet-resnet50-v1-fpn-512-coco-tf2">centernet-resnet50-v1-fpn-512-coco-tf2</a></li>
<li><a class="reference internal" href="#centernet-resnet50-v2-512-coco-tf2">centernet-resnet50-v2-512-coco-tf2</a></li>
<li><a class="reference internal" href="#deeplabv3-cityscapes-tf">deeplabv3-cityscapes-tf</a></li>
<li><a class="reference internal" href="#deeplabv3-mnv2-cityscapes-tf">deeplabv3-mnv2-cityscapes-tf</a></li>
<li><a class="reference internal" href="#efficientdet-d0-512-coco-tf2">efficientdet-d0-512-coco-tf2</a></li>
<li><a class="reference internal" href="#efficientdet-d0-coco-tf1">efficientdet-d0-coco-tf1</a></li>
<li><a class="reference internal" href="#efficientdet-d1-640-coco-tf2">efficientdet-d1-640-coco-tf2</a></li>
<li><a class="reference internal" href="#efficientdet-d1-coco-tf1">efficientdet-d1-coco-tf1</a></li>
<li><a class="reference internal" href="#efficientdet-d2-768-coco-tf2">efficientdet-d2-768-coco-tf2</a></li>
<li><a class="reference internal" href="#efficientdet-d2-coco-tf1">efficientdet-d2-coco-tf1</a></li>
<li><a class="reference internal" href="#efficientdet-d3-896-coco-tf2">efficientdet-d3-896-coco-tf2</a></li>
<li><a class="reference internal" href="#efficientdet-d3-coco-tf1">efficientdet-d3-coco-tf1</a></li>
<li><a class="reference internal" href="#efficientdet-d4-1024-coco-tf2">efficientdet-d4-1024-coco-tf2</a></li>
<li><a class="reference internal" href="#efficientdet-d4-coco-tf1">efficientdet-d4-coco-tf1</a></li>
<li><a class="reference internal" href="#efficientdet-d5-1280-coco-tf2">efficientdet-d5-1280-coco-tf2</a></li>
<li><a class="reference internal" href="#efficientdet-d5-coco-tf1">efficientdet-d5-coco-tf1</a></li>
<li><a class="reference internal" href="#efficientdet-d6-1280-coco-tf2">efficientdet-d6-1280-coco-tf2</a></li>
<li><a class="reference internal" href="#efficientdet-d6-coco-tf1">efficientdet-d6-coco-tf1</a></li>
<li><a class="reference internal" href="#efficientdet-d7-1536-coco-tf2">efficientdet-d7-1536-coco-tf2</a></li>
<li><a class="reference internal" href="#faster-rcnn-inception-resnet-atrous-v2-coco-tf">faster-rcnn-inception-resnet-atrous-v2-coco-tf</a></li>
<li><a class="reference internal" href="#faster-rcnn-inception-resnet-atrous-v2-lowproposals-coco-tf">faster-rcnn-inception-resnet-atrous-v2-lowproposals-coco-tf</a></li>
<li><a class="reference internal" href="#faster-rcnn-inception-v2-coco-tf">faster-rcnn-inception-v2-coco-tf</a></li>
<li><a class="reference internal" href="#faster-rcnn-nas-coco-tf">faster-rcnn-nas-coco-tf</a></li>
<li><a class="reference internal" href="#faster-rcnn-nas-lowproposals-coco-tf">faster-rcnn-nas-lowproposals-coco-tf</a></li>
<li><a class="reference internal" href="#faster-rcnn-resnet101-coco-tf">faster-rcnn-resnet101-coco-tf</a></li>
<li><a class="reference internal" href="#faster-rcnn-resnet101-lowproposals-coco-tf">faster-rcnn-resnet101-lowproposals-coco-tf</a></li>
<li><a class="reference internal" href="#faster-rcnn-resnet50-coco-tf">faster-rcnn-resnet50-coco-tf</a></li>
<li><a class="reference internal" href="#faster-rcnn-resnet50-lowproposals-coco-tf">faster-rcnn-resnet50-lowproposals-coco-tf</a></li>
<li><a class="reference internal" href="#inception-resnet-v2-imagenet-tf1">inception-resnet-v2-imagenet-tf1</a></li>
<li><a class="reference internal" href="#inception-v4-imagenet-tf1">inception-v4-imagenet-tf1</a></li>
<li><a class="reference internal" href="#mask-rcnn-inception-resnet-v2-atrous-coco-tf">mask-rcnn-inception-resnet-v2-atrous-coco-tf</a></li>
<li><a class="reference internal" href="#mask-rcnn-inception-v2-coco-tf">mask-rcnn-inception-v2-coco-tf</a></li>
<li><a class="reference internal" href="#mask-rcnn-resnet101-atrous-coco-tf">mask-rcnn-resnet101-atrous-coco-tf</a></li>
<li><a class="reference internal" href="#mask-rcnn-resnet50-atrous-coco-tf">mask-rcnn-resnet50-atrous-coco-tf</a></li>
<li><a class="reference internal" href="#mobilenet-v2-imagenet-tf1">mobilenet-v2-imagenet-tf1</a></li>
<li><a class="reference internal" href="#resnet-v1-50-imagenet-tf1">resnet-v1-50-imagenet-tf1</a></li>
<li><a class="reference internal" href="#resnet-v2-50-imagenet-tf1">resnet-v2-50-imagenet-tf1</a></li>
<li><a class="reference internal" href="#rfcn-resnet101-coco-tf">rfcn-resnet101-coco-tf</a></li>
<li><a class="reference internal" href="#ssd-inception-v2-coco-tf">ssd-inception-v2-coco-tf</a></li>
<li><a class="reference internal" href="#ssd-mobilenet-v1-coco-tf">ssd-mobilenet-v1-coco-tf</a></li>
<li><a class="reference internal" href="#ssd-mobilenet-v1-fpn-640-coco17">ssd-mobilenet-v1-fpn-640-coco17</a></li>
<li><a class="reference internal" href="#ssd-mobilenet-v1-fpn-coco-tf">ssd-mobilenet-v1-fpn-coco-tf</a></li>
<li><a class="reference internal" href="#ssd-mobilenet-v2-320-coco17">ssd-mobilenet-v2-320-coco17</a></li>
<li><a class="reference internal" href="#ssd-resnet50-fpn-coco-tf">ssd-resnet50-fpn-coco-tf</a></li>
<li><a class="reference internal" href="#vgg16-imagenet-tf1">vgg16-imagenet-tf1</a></li>
<li><a class="reference internal" href="#yolo-v2-coco-tf1">yolo-v2-coco-tf1</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
         <script src="../_static/js/voxel51-website.js"></script>
         <script src="../_static/js/custom.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->


  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>


  

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->


  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/features">Features</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>


  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>